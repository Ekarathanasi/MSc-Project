{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import illustris_python as il\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import interpolate\n",
    "\n",
    "from astropy import constants as const\n",
    "\n",
    "# Constants\n",
    "G = const.G.cgs.value  # Gravitational constant in cm^3 g^-1 s^-2\n",
    "m_p = const.m_p.cgs.value  # Proton mass in g\n",
    "c = const.c.cgs.value  # Speed of light in cm/s\n",
    "sigma_T = const.sigma_T.cgs.value  # Thomson cross-section in cm^2\n",
    "\n",
    "e_r = 0.2 #radiative accretion efficiency\n",
    "\n",
    "e_fh = 0.05 #high-accretion state \n",
    "e_fm = 0.2 #low-accretion state\n",
    "\n",
    "Msun = 1.989e33 # in grams\n",
    "Gyr_to_s = 3.15576e16 # in seconds\n",
    "\n",
    "h = 0.6774 #for illustrisTNG\n",
    "\n",
    "#Path of the simulation\n",
    "basePath = './sims.TNG/TNG100-1/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction data for z=1 same way with the data for illustris and illustrisTNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32 (6736881,)\n",
      "int32 (6736881, 6)\n"
     ]
    }
   ],
   "source": [
    "snapshot = 50\n",
    "\n",
    "#load the index of Subhalo table of the first (central) Subfind subhalo within this FoF group\n",
    "GroupFirstSub = il.groupcat.loadHalos(basePath,snapshot,fields=['GroupFirstSub'])\n",
    "print(GroupFirstSub.dtype, GroupFirstSub.shape)\n",
    "\n",
    "\n",
    "#load the integer counter of the total number of particles/cells, split into the six different types, in this group.\n",
    "GroupLenType = il.groupcat.loadHalos(basePath,snapshot,fields=['GroupLenType'])\n",
    "print(GroupLenType.dtype, GroupLenType.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22254"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Particle type number for black holes\n",
    "ptNumBH = il.snapshot.partTypeNum('bh')\n",
    "\n",
    "# Array of number of black holes in each halo\n",
    "numBH = GroupLenType[:, ptNumBH] #ptNumBH = 5\n",
    "\n",
    "# Find indices of halos that contain exactly one black hole and at least one subhalo\n",
    "w = np.where((numBH == 1) & (GroupFirstSub >= 0))[0]\n",
    "\n",
    "# Find the first subhalo in each of these halos\n",
    "galaxies = GroupFirstSub[w]\n",
    "\n",
    "len(galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ids of 10 most massive galaxies\n",
    "ids = galaxies[0:10000]\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to pandas DataFrame\n",
    "df = pd.DataFrame(ids, columns=['ID'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID\n",
      "0  199097\n",
      "1  210307\n",
      "2  212195\n",
      "3  222547\n",
      "4  223589\n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('z=1.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "χ values for χ_rate >= 1:\n",
      "3\n",
      "χ values for χ_rate < 1:\n",
      "9997\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store the fraction χ of the Eddington accretion rate values\n",
    "χ_rate_list1 = []  # for χ_rate >= 1, high accretion state\n",
    "χ_rate_list2 = []  # for χ_rate < 1, low accretion state\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\", \"BH_MdotEddington\"]\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting χ_rate will be np.nan.\n",
    "        \n",
    "    # Calculate the BH eddington.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_MdotEddington' in blackholes and len(blackholes['BH_MdotEddington']) > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    else:  \n",
    "        bhedd = np.nan  # Set to np.nan so that the resulting χ_rate will be np.nan.\n",
    "        \n",
    "    # Calculate χ_rate\n",
    "    χ_rate = (bhdot / bhedd)\n",
    "        \n",
    "    # Append χ_rate to the appropriate list\n",
    "    if χ_rate >= 1:\n",
    "        χ_rate_list1.append(χ_rate)\n",
    "    else:\n",
    "        χ_rate_list2.append(χ_rate)\n",
    "\n",
    "# Print fraction χ values\n",
    "print(\"χ values for χ_rate >= 1:\")\n",
    "print(len(χ_rate_list1))\n",
    "\n",
    "print(\"χ values for χ_rate < 1:\")\n",
    "print(len(χ_rate_list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Energy feed \n",
    "<br>\n",
    "2) Bolometric luminosity\n",
    "<br>\n",
    "3) SubhaloSFRinHalfRad\n",
    "<br>\n",
    "4) Average divergence velocity\n",
    "<br>\n",
    "5) SubhaloVelDisp\n",
    "<br>\n",
    "6) BH_Mdot\n",
    "<br>\n",
    "7) BH_Mass\n",
    "<br>\n",
    "8) SubhaloGasMetallicitySfr\n",
    "<br>\n",
    "9) SubhaloStellarPhotometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "χ and λ is the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store of fraction χ of the Eddington accretion rate values\n",
    "λ_rate_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\", \"BH_MdotEddington\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "        \n",
    "    # Calculate the BH eddington.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_MdotEddington' in blackholes and len(blackholes['BH_MdotEddington']) > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    else:  \n",
    "        bhedd = np.nan  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate λ_rate\n",
    "    λ_rate = (bhdot / bhedd)\n",
    "\n",
    "    \n",
    "    # Append λ_rate to the list\n",
    "    λ_rate_list.append(λ_rate)\n",
    "\n",
    "\n",
    "print(\"λ values:\")\n",
    "print(len(λ_rate_list))\n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['λ'] = λ_rate_list\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_feed values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the feedback energy of the AGN values\n",
    "E_feed_list = []\n",
    "\n",
    "\n",
    "Msun = 1.989e33 # in grams\n",
    "Gyr_to_s = 3.15576e16 # in seconds\n",
    "h = 0.6774\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting feedback energy will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate feedback energy\n",
    "    E_feed = e_fm * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append feedback energy to the list\n",
    "    E_feed_list.append(np.log10(E_feed))\n",
    "\n",
    "\n",
    "# Print feedback energy values\n",
    "print(\"E_feed values:\")\n",
    "\n",
    "print(len(E_feed_list))\n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['E_feed'] = E_feed_list\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bol Luminosity values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the bolometric luminosity values\n",
    "L_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting L_bol will be np.nan.\n",
    "\n",
    "    # Calculate L_bol\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append bolometric luminosity to the list\n",
    "    L_list.append(np.log10(L_bol))\n",
    "\n",
    "\n",
    "# Print bolometric luminosity values\n",
    "print(\"Bol Luminosity values:\")\n",
    "print(len(L_list))\n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['L_bol'] = L_list\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFR values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store Star formation rate\n",
    "sfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    #load the galaxies\n",
    "    sfr = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    #extract the value of the sfr\n",
    "    sfr_value = sfr['SubhaloSFRinHalfRad']\n",
    "    sfr_values.append(sfr_value)\n",
    "    \n",
    "print(\"SFR values:\")\n",
    "print(len(sfr_values))\n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['SFRinhalfrad'] = sfr_values\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adhust as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the particle data for the subhalo\n",
    "    part_data = il.snapshot.loadSubhalo(basePath, snapshot, id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "    \n",
    "    agn_position = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    agn_position = agn_position['SubhaloPos']\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "# Print the average divergence\n",
    "print(\"Average divergence velocity values:\")\n",
    "print(len(avg_divergence_list))\n",
    "\n",
    "#read the file    \n",
    "df = pd.read_csv('z=1.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence'] = avg_divergence_list\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average radial velocity values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "def calculate_radial_velocity(positions, velocities, agn_position):\n",
    "    # Calculate the relative positions and distances of the particles\n",
    "    relative_positions = positions - agn_position\n",
    "    distances = np.linalg.norm(relative_positions, axis=1)\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = np.sum(relative_positions * velocities, axis=1) / distances\n",
    "\n",
    "    return radial_velocities\n",
    "\n",
    "# Define lists to store the results\n",
    "average_radial_velocity_list = []\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snapshot, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snapshot, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = calculate_radial_velocity(part_data['Coordinates'], part_data['Velocities'], agn_position)\n",
    "\n",
    "    # Calculate the average radial velocity\n",
    "    average_radial_velocity = np.mean(radial_velocities)\n",
    "    \n",
    "    average_radial_velocity_list.append(average_radial_velocity)\n",
    "\n",
    "# Print the average divergence\n",
    "print(\"Average radial velocity values:\")\n",
    "print(len(average_radial_velocity_list))\n",
    "\n",
    "#read the file    \n",
    "df = pd.read_csv('z=1.csv')\n",
    "#append them to the new column \n",
    "df['Average radial velocity'] = average_radial_velocity_list\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velelocity values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store Star formation rate\n",
    "Veldip_values = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    #load the galaxies\n",
    "    Veldip = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    #extract the value of the velocity\n",
    "    Veldip_value = sfr['SubhaloVelDisp']\n",
    "    Veldip_values.append(Veldip_value)\n",
    "    \n",
    "print(\"Velelocity values:\")\n",
    "print(len(Veldip_values))\n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['Velocity disp'] = Veldip_values\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhmdot:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store BHmdot\n",
    "bhmdot_values = []\n",
    "\n",
    "fields = 'BH_Mdot'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BHmdot.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_dot = bh_data[0] * ((1e10 * Msun) / (h * Gyr_to_s)) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mdot' in bh_data and len(bh_data['BH_Mdot']) > 0:  # Check if there is BH data.\n",
    "        bh_dot = bh_data['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  # If no BH data, set the BHmdot to zero.\n",
    "        bh_dot = 0.0\n",
    "        \n",
    "    #covert the BHmdot to log10 \n",
    "    bh_dot = np.log10(bh_dot)\n",
    "\n",
    "    # Append the BHmdot to the list.\n",
    "    bhmdot_values.append(bh_dot)\n",
    "    \n",
    "    \n",
    "# Print the BHmdot\n",
    "print(\"Bhmdot:\")\n",
    "print(len(bhmdot_values)) \n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['Bhmdot'] = bhmdot_values\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackhole Masses:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store BH masses\n",
    "bhmass_values = []\n",
    "\n",
    "fields = 'BH_Mass'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_mass = bh_data[0] * ((1e10) / h) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mass' in bh_data and len(bh_data['BH_Mass']) > 0:  # Check if there is BH data.\n",
    "        bh_mass = bh_data['BH_Mass'][0] * ((1e10) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_mass = np.log10(bh_mass)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmass_values.append(bh_mass)\n",
    "    \n",
    "    \n",
    "# Print the bh masess\n",
    "print(\"Blackhole Masses:\")\n",
    "print(len(bhmass_values)) \n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['Blackhole Masses'] = bhmass_values\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metallicity SFR values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store Metallicity Star formation rate\n",
    "msfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load the galaxy data\n",
    "    msfr = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    # Extract the value of the metallicity SFR\n",
    "    msfr_value = msfr['SubhaloGasMetallicitySfr']\n",
    "    msfr_values.append(msfr_value)\n",
    "\n",
    "print(\"Metallicity SFR values:\")\n",
    "print(len(msfr_values))\n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['MSFR'] = msfr_values\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-band values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store U-band photometric data\n",
    "uv_values = []\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load the galaxy data\n",
    "    photometrics = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    # Extract the U-band photometric data (which is at index 0)\n",
    "    uv_band = photometrics['SubhaloStellarPhotometrics'][0]\n",
    "    uv_values.append(uv_band)\n",
    "    \n",
    "print(\"U-band values:\")\n",
    "print(len(uv_values))\n",
    "\n",
    "df = pd.read_csv('z=1.csv')\n",
    "df['UV_Band'] = uv_values\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID     E_feed      L_bol  SFRinhalfrad  Average divergence  \\\n",
      "0  199097  44.350290  44.350290      0.000000           -0.611396   \n",
      "1  210307  43.252561  43.252561      0.414761           -0.348660   \n",
      "2  212195  44.126306  44.126306      0.247022            4.219759   \n",
      "3  222547  43.732386  43.732386      0.000000            2.245786   \n",
      "4  223589  43.102978  43.102978      0.293753            3.240826   \n",
      "\n",
      "   Velocity disp     Bhmdot  Blackhole Masses      MSFR    UV_Band  \n",
      "0      59.869755  24.095618          8.774169  0.012307 -22.445345  \n",
      "1      59.869755  22.997890          8.478360  0.012681 -23.001787  \n",
      "2      59.869755  23.871635          8.609567  0.008637 -22.212519  \n",
      "3      59.869755  23.477714          8.629783  0.010330 -22.015049  \n",
      "4      59.869755  22.848307          8.642096  0.009274 -22.436623  \n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('z=1.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0       59.869755\n",
       "1       59.869755\n",
       "2       59.869755\n",
       "3       59.869755\n",
       "4       59.869755\n",
       "5       59.869755\n",
       "6       59.869755\n",
       "7       59.869755\n",
       "8       59.869755\n",
       "9       59.869755\n",
       "10      59.869755\n",
       "11      59.869755\n",
       "12      59.869755\n",
       "13      59.869755\n",
       "14      59.869755\n",
       "15      59.869755\n",
       "16      59.869755\n",
       "17      59.869755\n",
       "18      59.869755\n",
       "19      59.869755\n",
       "20      59.869755\n",
       "21      59.869755\n",
       "22      59.869755\n",
       "23      59.869755\n",
       "24      59.869755\n",
       "25      59.869755\n",
       "26      59.869755\n",
       "27      59.869755\n",
       "28      59.869755\n",
       "29      59.869755\n",
       "          ...    \n",
       "9970    59.869755\n",
       "9971    59.869755\n",
       "9972    59.869755\n",
       "9973    59.869755\n",
       "9974    59.869755\n",
       "9975    59.869755\n",
       "9976    59.869755\n",
       "9977    59.869755\n",
       "9978    59.869755\n",
       "9979    59.869755\n",
       "9980    59.869755\n",
       "9981    59.869755\n",
       "9982    59.869755\n",
       "9983    59.869755\n",
       "9984    59.869755\n",
       "9985    59.869755\n",
       "9986    59.869755\n",
       "9987    59.869755\n",
       "9988    59.869755\n",
       "9989    59.869755\n",
       "9990    59.869755\n",
       "9991    59.869755\n",
       "9992    59.869755\n",
       "9993    59.869755\n",
       "9994    59.869755\n",
       "9995    59.869755\n",
       "9996    59.869755\n",
       "9997    59.869755\n",
       "9998    59.869755\n",
       "9999    59.869755\n",
       "Name: Velocity disp, Length: 10000, dtype: float64>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Velocity disp'].unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's dicided we dont need Velocity dispersion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a column (e.g., \"column_to_drop\")\n",
    "df = df.drop('Velocity disp', axis=1)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv('z=1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction data for z=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32 (6572201,)\n",
      "int32 (6572201, 6)\n"
     ]
    }
   ],
   "source": [
    "snapshot = 67\n",
    "\n",
    "#load the index of Subhalo table of the first (central) Subfind subhalo within this FoF group\n",
    "GroupFirstSub = il.groupcat.loadHalos(basePath,snapshot,fields=['GroupFirstSub'])\n",
    "print(GroupFirstSub.dtype, GroupFirstSub.shape)\n",
    "\n",
    "\n",
    "#load the integer counter of the total number of particles/cells, split into the six different types, in this group.\n",
    "GroupLenType = il.groupcat.loadHalos(basePath,snapshot,fields=['GroupLenType'])\n",
    "print(GroupLenType.dtype, GroupLenType.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22824"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Particle type number for black holes\n",
    "ptNumBH = il.snapshot.partTypeNum('bh')\n",
    "\n",
    "# Array of number of black holes in each halo\n",
    "numBH = GroupLenType[:, ptNumBH] #ptNumBH = 5\n",
    "\n",
    "# Find indices of halos that contain exactly one black hole and at least one subhalo\n",
    "w = np.where((numBH == 1) & (GroupFirstSub >= 0))[0]\n",
    "\n",
    "# Find the first subhalo in each of these halos\n",
    "galaxies = GroupFirstSub[w]\n",
    "\n",
    "len(galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ids of 10000 most massive galaxies\n",
    "ids = galaxies[0:10000]\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to pandas DataFrame\n",
    "df = pd.DataFrame(ids, columns=['ID'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID\n",
      "0  277421\n",
      "1  288670\n",
      "2  300406\n",
      "3  303392\n",
      "4  313327\n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "χ values for χ_rate >= 1:\n",
      "1\n",
      "χ values for χ_rate < 1:\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store the fraction χ of the Eddington accretion rate values\n",
    "χ_rate_list1 = []  # for χ_rate >= 1\n",
    "χ_rate_list2 = []  # for χ_rate < 1\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\", \"BH_MdotEddington\"]\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting χ_rate will be np.nan.\n",
    "        \n",
    "    # Calculate the BH eddington.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_MdotEddington' in blackholes and len(blackholes['BH_MdotEddington']) > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    else:  \n",
    "        bhedd = np.nan  # Set to np.nan so that the resulting χ_rate will be np.nan.\n",
    "\n",
    "    # Calculate χ_rate\n",
    "    χ_rate = (bhdot / bhedd)\n",
    "        \n",
    "    # Append χ_rate to the appropriate list\n",
    "    if χ_rate >= 1:\n",
    "        χ_rate_list1.append(χ_rate)\n",
    "    else:\n",
    "        χ_rate_list2.append(χ_rate)\n",
    "\n",
    "# Print fraction χ values\n",
    "print(\"χ values for χ_rate >= 1:\")\n",
    "print(len(χ_rate_list1))\n",
    "\n",
    "print(\"χ values for χ_rate < 1:\")\n",
    "print(len(χ_rate_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store of fraction χ of the Eddington accretion rate values\n",
    "λ_rate_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\", \"BH_MdotEddington\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "        \n",
    "    # Calculate the BH eddington.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_MdotEddington' in blackholes and len(blackholes['BH_MdotEddington']) > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    else:  \n",
    "        bhedd = np.nan  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate λ_rate\n",
    "    λ_rate = (bhdot / bhedd)\n",
    "\n",
    "    \n",
    "    # Append λ_rate to the list\n",
    "    λ_rate_list.append(λ_rate)\n",
    "\n",
    "\n",
    "print(\"λ values:\")\n",
    "print(len(λ_rate_list))\n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['λ'] = λ_rate_list\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_feed values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the feedback energy of the AGN values\n",
    "E_feed_list = []\n",
    "\n",
    "\n",
    "Msun = 1.989e33 # in grams\n",
    "Gyr_to_s = 3.15576e16 # in seconds\n",
    "h = 0.6774\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting feedback energy will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate feedback energy\n",
    "    E_feed = e_fm * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append feedback energy to the list\n",
    "    E_feed_list.append(np.log10(E_feed))\n",
    "\n",
    "\n",
    "# Print feedback energy values\n",
    "print(\"E_feed values:\")\n",
    "\n",
    "print(len(E_feed_list))\n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['E_feed'] = E_feed_list\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bol Luminosity values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the bolometric luminosity values\n",
    "L_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting L_bol will be np.nan.\n",
    "\n",
    "    # Calculate L_bol\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append bolometric luminosity to the list\n",
    "    L_list.append(np.log10(L_bol))\n",
    "\n",
    "\n",
    "# Print bolometric luminosity values\n",
    "print(\"Bol Luminosity values:\")\n",
    "print(len(L_list))\n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['L_bol'] = L_list\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFR values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store Star formation rate\n",
    "sfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    #load the galaxies\n",
    "    sfr = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    #extract the value of the sfr\n",
    "    sfr_value = sfr['SubhaloSFRinHalfRad']\n",
    "    sfr_values.append(sfr_value)\n",
    "    \n",
    "print(\"SFR values:\")\n",
    "print(len(sfr_values))\n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['SFRinhalfrad'] = sfr_values\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Check if 'Coordinates' is in the loaded data\n",
    "    if 'Coordinates' not in part_data:\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 10  # This value can be adjusted as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the particle data for the subhalo\n",
    "    part_data = il.snapshot.loadSubhalo(basePath, snapshot, id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "    \n",
    "    agn_position = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    agn_position = agn_position['SubhaloPos']\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "# Print the average divergence\n",
    "print(\"Average divergence velocity values:\")\n",
    "print(len(avg_divergence_list))\n",
    "\n",
    "#read the file    \n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence'] = avg_divergence_list\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average radial velocity values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "def calculate_radial_velocity(positions, velocities, agn_position):\n",
    "    # Calculate the relative positions and distances of the particles\n",
    "    relative_positions = positions - agn_position\n",
    "    distances = np.linalg.norm(relative_positions, axis=1)\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = np.sum(relative_positions * velocities, axis=1) / distances\n",
    "\n",
    "    return radial_velocities\n",
    "\n",
    "# Define lists to store the results\n",
    "average_radial_velocity_list = []\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snapshot, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snapshot, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = calculate_radial_velocity(part_data['Coordinates'], part_data['Velocities'], agn_position)\n",
    "\n",
    "    # Calculate the average radial velocity\n",
    "    average_radial_velocity = np.mean(radial_velocities)\n",
    "    \n",
    "    average_radial_velocity_list.append(average_radial_velocity)\n",
    "\n",
    "# Print the average divergence\n",
    "print(\"Average radial velocity values:\")\n",
    "print(len(average_radial_velocity_list))\n",
    "\n",
    "#read the file    \n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "#append them to the new column \n",
    "df['Average radial velocity'] = average_radial_velocity_list\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store BH masses\n",
    "bhmdot_values = []\n",
    "\n",
    "fields = 'BH_Mdot'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_dot = bh_data[0] * ((1e10 * Msun) / (h * Gyr_to_s)) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mdot' in bh_data and len(bh_data['BH_Mdot']) > 0:  # Check if there is BH data.\n",
    "        bh_dot = bh_data['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_dot = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_dot = np.log10(bh_dot)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmdot_values.append(bh_dot)\n",
    "    \n",
    "    \n",
    "# Print the average divergence\n",
    "print(\"Bhmdot:\")\n",
    "print(len(bhmdot_values)) \n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['Bhmdot'] = bhmdot_values\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store BH masses\n",
    "bhmass_values = []\n",
    "\n",
    "fields = 'BH_Mass'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_mass = bh_data[0] * ((1e10) / h) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mass' in bh_data and len(bh_data['BH_Mass']) > 0:  # Check if there is BH data.\n",
    "        bh_mass = bh_data['BH_Mass'][0] * ((1e10) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_mass = np.log10(bh_mass)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmass_values.append(bh_mass)\n",
    "    \n",
    "    \n",
    "# Print the average divergence\n",
    "print(\"Blackhole Masses:\")\n",
    "print(len(bhmass_values)) \n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['Blackhole Masses'] = bhmass_values\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store metallicity Star formation rate\n",
    "msfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load the galaxy data\n",
    "    msfr = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    # Extract the value of the metallicity SFR\n",
    "    msfr_value = msfr['SubhaloGasMetallicitySfr']\n",
    "    msfr_values.append(msfr_value)\n",
    "\n",
    "print(\"Metallicity SFR values:\")\n",
    "print(len(msfr_values))\n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['MSFR'] = msfr_values\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store U-band photometric data\n",
    "uv_values = []\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load the galaxy data\n",
    "    photometrics = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    # Extract the U-band photometric data (which is at index 0)\n",
    "    uv_band = photometrics['SubhaloStellarPhotometrics'][0]\n",
    "    uv_values.append(uv_band)\n",
    "    \n",
    "print(\"U-band values:\")\n",
    "print(len(uv_values))\n",
    "\n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "df['UV_Band'] = uv_values\n",
    "df.to_csv('z=0_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('z=0_5.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction data for z=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32 (6291349,)\n",
      "int32 (6291349, 6)\n"
     ]
    }
   ],
   "source": [
    "snapshot = 99\n",
    "\n",
    "#load the index of Subhalo table of the first (central) Subfind subhalo within this FoF group\n",
    "GroupFirstSub = il.groupcat.loadHalos(basePath,snapshot,fields=['GroupFirstSub'])\n",
    "print(GroupFirstSub.dtype, GroupFirstSub.shape)\n",
    "\n",
    "\n",
    "#load the integer counter of the total number of particles/cells, split into the six different types, in this group.\n",
    "GroupLenType = il.groupcat.loadHalos(basePath,snapshot,fields=['GroupLenType'])\n",
    "print(GroupLenType.dtype, GroupLenType.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22671"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Particle type number for black holes\n",
    "ptNumBH = il.snapshot.partTypeNum('bh')\n",
    "\n",
    "# Array of number of black holes in each halo\n",
    "numBH = GroupLenType[:, ptNumBH] #ptNumBH = 5\n",
    "\n",
    "# Find indices of halos that contain exactly one black hole and at least one subhalo\n",
    "w = np.where((numBH == 1) & (GroupFirstSub >= 0))[0]\n",
    "\n",
    "# Find the first subhalo in each of these halos\n",
    "galaxies = GroupFirstSub[w]\n",
    "\n",
    "len(galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ids of 10000 most massive galaxies\n",
    "ids = galaxies[0:10000]\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to pandas DataFrame\n",
    "df = pd.DataFrame(ids, columns=['ID'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID\n",
      "0  356678\n",
      "1  359811\n",
      "2  377398\n",
      "3  381608\n",
      "4  384914\n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('z=0.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "χ values for χ_rate >= 1:\n",
      "0\n",
      "χ values for χ_rate < 1:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store the fraction χ of the Eddington accretion rate values\n",
    "χ_rate_list1 = []  # for χ_rate >= 1\n",
    "χ_rate_list2 = []  # for χ_rate < 1\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\", \"BH_MdotEddington\"]\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting χ_rate will be np.nan.\n",
    "        \n",
    "    # Calculate the BH eddington.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_MdotEddington' in blackholes and len(blackholes['BH_MdotEddington']) > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    else:  \n",
    "        bhedd = np.nan  # Set to np.nan so that the resulting χ_rate will be np.nan.\n",
    "\n",
    "    # Calculate χ_rate\n",
    "    χ_rate = (bhdot / bhedd)\n",
    "    \n",
    "    # Append χ_rate to the appropriate list\n",
    "    if χ_rate >= 1:\n",
    "        χ_rate_list1.append(χ_rate)\n",
    "    else:\n",
    "        χ_rate_list2.append(χ_rate)\n",
    "\n",
    "# Print fraction χ values\n",
    "print(\"χ values for χ_rate >= 1:\")\n",
    "print(len(χ_rate_list1))\n",
    "\n",
    "print(\"χ values for χ_rate < 1:\")\n",
    "print(len(χ_rate_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store of fraction χ of the Eddington accretion rate values\n",
    "λ_rate_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\", \"BH_MdotEddington\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0]\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "        \n",
    "    # Calculate the BH eddington.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    elif isinstance(blackholes, dict) and 'BH_MdotEddington' in blackholes and len(blackholes['BH_MdotEddington']) > 0 and blackholes['BH_MdotEddington'][0] != 0:  \n",
    "        bhedd = blackholes['BH_MdotEddington'][0]\n",
    "    else:  \n",
    "        bhedd = np.nan  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate λ_rate\n",
    "    λ_rate = (bhdot / bhedd)\n",
    "\n",
    "    \n",
    "    # Append λ_rate to the list\n",
    "    λ_rate_list.append(λ_rate)\n",
    "\n",
    "\n",
    "print(\"λ values:\")\n",
    "print(len(λ_rate_list))\n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['λ'] = λ_rate_list\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_feed values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the feedback energy of the AGN values\n",
    "E_feed_list = []\n",
    "\n",
    "\n",
    "Msun = 1.989e33 # in grams\n",
    "Gyr_to_s = 3.15576e16 # in seconds\n",
    "h = 0.6774\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting feedback energy will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate feedback energy\n",
    "    E_feed = e_fm * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append feedback energy to the list\n",
    "    E_feed_list.append(np.log10(E_feed))\n",
    "\n",
    "\n",
    "# Print feedback energy values\n",
    "print(\"E_feed values:\")\n",
    "\n",
    "print(len(E_feed_list))\n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['E_feed'] = E_feed_list\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bol Luminosity values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the bolometric luminosity values\n",
    "L_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting L_bol will be np.nan.\n",
    "\n",
    "    # Calculate L_bol\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append bolometric luminosity to the list\n",
    "    L_list.append(np.log10(L_bol))\n",
    "\n",
    "\n",
    "# Print bolometric luminosity values\n",
    "print(\"Bol Luminosity values:\")\n",
    "print(len(L_list))\n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['L_bol'] = L_list\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFR values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store Star formation rate\n",
    "sfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    #load the galaxies\n",
    "    sfr = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    #extract the value of the sfr\n",
    "    sfr_value = sfr['SubhaloSFRinHalfRad']\n",
    "    sfr_values.append(sfr_value)\n",
    "    \n",
    "print(\"SFR values:\")\n",
    "print(len(sfr_values))\n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['SFRinhalfrad'] = sfr_values\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Check if 'Coordinates' is in the loaded data\n",
    "    if 'Coordinates' not in part_data:\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 10  # This value can be adjusted as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the particle data for the subhalo\n",
    "    part_data = il.snapshot.loadSubhalo(basePath, snapshot, id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "    \n",
    "    agn_position = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    agn_position = agn_position['SubhaloPos']\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "# Print the average divergence\n",
    "print(\"Average divergence velocity values:\")\n",
    "print(avg_divergence_list)\n",
    "\n",
    "#read the file    \n",
    "df = pd.read_csv('z=0.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence'] = avg_divergence_list\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average radial velocity values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "def calculate_radial_velocity(positions, velocities, agn_position):\n",
    "    # Calculate the relative positions and distances of the particles\n",
    "    relative_positions = positions - agn_position\n",
    "    distances = np.linalg.norm(relative_positions, axis=1)\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = np.sum(relative_positions * velocities, axis=1) / distances\n",
    "\n",
    "    return radial_velocities\n",
    "\n",
    "# Define lists to store the results\n",
    "average_radial_velocity_list = []\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snapshot, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snapshot, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = calculate_radial_velocity(part_data['Coordinates'], part_data['Velocities'], agn_position)\n",
    "\n",
    "    # Calculate the average radial velocity\n",
    "    average_radial_velocity = np.mean(radial_velocities)\n",
    "    \n",
    "    average_radial_velocity_list.append(average_radial_velocity)\n",
    "\n",
    "# Print the average divergence\n",
    "print(\"Average radial velocity values:\")\n",
    "print(len(average_radial_velocity_list))\n",
    "\n",
    "#read the file    \n",
    "df = pd.read_csv('z=0.csv')\n",
    "#append them to the new column \n",
    "df['Average radial velocity'] = average_radial_velocity_list\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhmdot:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store BH masses\n",
    "bhmdot_values = []\n",
    "\n",
    "fields = 'BH_Mdot'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_dot = bh_data[0] * ((1e10 * Msun) / (h * Gyr_to_s)) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mdot' in bh_data and len(bh_data['BH_Mdot']) > 0:  # Check if there is BH data.\n",
    "        bh_dot = bh_data['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_dot = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_dot = np.log10(bh_dot)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmdot_values.append(bh_dot)\n",
    "    \n",
    "    \n",
    "# Print the average divergence\n",
    "print(\"Bhmdot:\")\n",
    "print(len(bhmdot_values)) \n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['Bhmdot'] = bhmdot_values\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackhole Masses:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store BH masses\n",
    "bhmass_values = []\n",
    "\n",
    "fields = 'BH_Mass'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for id in ids:\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_mass = bh_data[0] * ((1e10) / h) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mass' in bh_data and len(bh_data['BH_Mass']) > 0:  # Check if there is BH data.\n",
    "        bh_mass = bh_data['BH_Mass'][0] * ((1e10) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_mass = np.log10(bh_mass)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmass_values.append(bh_mass)\n",
    "    \n",
    "    \n",
    "# Print the average divergence\n",
    "print(\"Blackhole Masses:\")\n",
    "print(len(bhmass_values)) \n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['Blackhole Masses'] = bhmass_values\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metallicity SFR values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store Metallicity Star formation rate\n",
    "msfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load the galaxy data\n",
    "    msfr = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    # Extract the value of the metallicity SFR\n",
    "    msfr_value = msfr['SubhaloGasMetallicitySfr']\n",
    "    msfr_values.append(msfr_value)\n",
    "\n",
    "print(\"Metallicity SFR values:\")\n",
    "print(len(msfr_values))\n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['MSFR'] = msfr_values\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-band values:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# List to store U-band photometric data\n",
    "uv_values = []\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Load the galaxy data\n",
    "    photometrics = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)\n",
    "    # Extract the U-band photometric data (which is at index 0)\n",
    "    uv_band = photometrics['SubhaloStellarPhotometrics'][0]\n",
    "    uv_values.append(uv_band)\n",
    "    \n",
    "print(\"U-band values:\")\n",
    "print(len(uv_values))\n",
    "\n",
    "df = pd.read_csv('z=0.csv')\n",
    "df['UV_Band'] = uv_values\n",
    "df.to_csv('z=0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID     E_feed      L_bol  SFRinhalfrad  Average divergence     Bhmdot  \\\n",
      "0  356678  43.172570  43.172570           0.0           -0.933217  22.917899   \n",
      "1  359811  42.544454  42.544454           0.0           -1.404874  22.289783   \n",
      "2  377398  42.564474  42.564474           0.0            0.805930  22.309802   \n",
      "3  381608  41.487624  41.487624           0.0            0.321204  21.232953   \n",
      "4  384914  42.692935  42.692935           0.0           -0.319989  22.438263   \n",
      "\n",
      "   Blackhole Masses      MSFR    UV_Band  \n",
      "0          8.905789  0.000000 -21.000128  \n",
      "1          9.003120  0.005017 -20.239038  \n",
      "2          8.776723  0.013295 -20.981514  \n",
      "3          8.836200  0.000000 -20.463696  \n",
      "4          8.741881  0.005737 -20.651108  \n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('z=0.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for getting the Average Divergence velocity of gas in Halo, though due to immense time processing of more than 12 hours, it was left out of the Data and also because of the decontamination of the Halo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adjusted as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID\n",
    "for id in ids:\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snapshot, subhaloID=id)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snapshot, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snapshot, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "# Print the average divergence\n",
    "print(\"Average divergence velocity values:\")\n",
    "print(len(avg_divergence_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
