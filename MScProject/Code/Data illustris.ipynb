{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thats for API propose, can been found in the IllustrisTNG example for API\n",
    "import requests\n",
    "\n",
    "def get(path, params=None):\n",
    "    # make HTTP GET request to path\n",
    "    headers = {\"api-key\":\"83fb2a511946e50d7d8eb5c334bbc58c\"}\n",
    "    r = requests.get(path, params=params, headers=headers)\n",
    "\n",
    "    # raise exception if response code is not HTTP SUCCESS (200)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json() # parse json responses automatically\n",
    "\n",
    "    if 'content-disposition' in r.headers:\n",
    "        filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        return filename # return the filename string\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import illustris_python as il\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import interpolate\n",
    "\n",
    "from astropy import constants as const\n",
    "\n",
    "# Constants\n",
    "G = const.G.cgs.value  # Gravitational constant in cm^3 g^-1 s^-2\n",
    "m_p = const.m_p.cgs.value  # Proton mass in g\n",
    "c = const.c.cgs.value  # Speed of light in cm/s\n",
    "sigma_T = const.sigma_T.cgs.value  # Thomson cross-section in cm^2\n",
    "\n",
    "e_r = 0.2 #radiative accretion efficiency\n",
    "\n",
    "e_fh = 0.05 #high-accretion state \n",
    "e_fm = 0.2 #low-accretion state\n",
    "\n",
    "Msun = 1.989e33 # in grams\n",
    "Gyr_to_s = 3.15576e16 # in seconds\n",
    "\n",
    "h = 0.6774 #for illustrisTNG\n",
    "\n",
    "#Path of the simulation in Jupyterlab\n",
    "basePath = './sims.illustris/Illustris-1/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Galaxy selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint32 (7713601,)\n",
      "uint32 (7713601, 6)\n"
     ]
    }
   ],
   "source": [
    "#load the index of Subhalo table of the first (central) Subfind subhalo within this FoF group\n",
    "GroupFirstSub = il.groupcat.loadHalos(basePath,135,fields=['GroupFirstSub'])\n",
    "print(GroupFirstSub.dtype, GroupFirstSub.shape)\n",
    "\n",
    "\n",
    "#load the integer counter of the total number of particles/cells, split into the six different types, in this group.\n",
    "GroupLenType = il.groupcat.loadHalos(basePath,135,fields=['GroupLenType'])\n",
    "print(GroupLenType.dtype, GroupLenType.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Particle type number for black holes\n",
    "ptNumBH = il.snapshot.partTypeNum('bh')\n",
    "\n",
    "# Array of number of black holes in each halo\n",
    "numBH = GroupLenType[:, ptNumBH] #ptNumBH = 5\n",
    "\n",
    "# Find indices of halos that contain exactly one black hole and at least one subhalo\n",
    "w = np.where((numBH == 1) & (GroupFirstSub >= 0))[0]\n",
    "\n",
    "# Find the first subhalo in each of these halos\n",
    "galaxies = GroupFirstSub[w]\n",
    "\n",
    "len(galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([305959, 312924, 321863, 322384, 324170, 334336, 337748, 345367,\n",
       "       345729, 347122], dtype=uint32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ids of 10 most massive galaxies\n",
    "ids = galaxies[0:10]\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the galaxies if the have supermassive black hole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305959 8.778439658461915 1\n",
      "312924 8.74446968827434 1\n",
      "321863 8.830844473012226 1\n",
      "322384 8.527146794943475 1\n",
      "324170 8.553454446999773 1\n",
      "334336 8.400088845975754 1\n",
      "337748 8.439903497920138 1\n",
      "345367 8.41405014138325 1\n",
      "345729 8.675091232257937 1\n",
      "347122 8.597645965866906 1\n"
     ]
    }
   ],
   "source": [
    "for id in ids:\n",
    "    url = \"http://www.tng-project.org/api/Illustris-1/snapshots/z=0/subhalos/\" + str(id)\n",
    "    subhalo = get(url)\n",
    "    print(id, np.log10(subhalo['mass_bhs'] *((1e10) / h)), subhalo['len_bhs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a CSV file! \n",
    "##### With the data that we want to use in order to make the graphs/diagrams for galaxy id=305959 which is the most massive galaxy with one black hole (SMBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progenitor of 305959 at snap=135 is 305959\n",
      "Progenitor of 305959 at snap=103 is 192798\n",
      "Progenitor of 305959 at snap=85 is 195558\n",
      "Progenitor of 305959 at snap=68 is 106855\n",
      "Progenitor of 305959 at snap=60 is 68043\n",
      "Progenitor of 305959 at snap=54 is 55141\n",
      "[55141, 68043, 106855, 195558, 192798, 305959]\n"
     ]
    }
   ],
   "source": [
    "ids = [305959] #galaxy id\n",
    "target_snaps = [135, 103, 85, 68, 60, 54]  # list of target snapshots(redshifts) here \n",
    "\n",
    "# the target snapshots list are the 6 out the 10 full snapshots that illustris-1 have \n",
    "# 135 snapshots corresponds to z=0 and the 54 snapshot to z=4\n",
    "\n",
    "#this code. tries to find the galaxies in previous redshifts\n",
    "progenitor_ids_list = []\n",
    "\n",
    "for id in ids:\n",
    "    id_progenitors = []\n",
    "    start_url = \"http://www.tng-project.org/api/Illustris-1/snapshots/z=0/subhalos/\" + str(id)\n",
    "    sub = get(start_url)\n",
    "    current_snap = 135\n",
    "\n",
    "    for snap in target_snaps:\n",
    "        while current_snap > snap:\n",
    "            # request the full subhalo details of the progenitor by following the sublink URL\n",
    "            try:\n",
    "                sub = get(sub['related']['sublink_progenitor'])\n",
    "                current_snap = sub['snap']\n",
    "            except KeyError:  # KeyError occurs if there's no progenitor\n",
    "                break  # exit the while loop and go to the next snap\n",
    "\n",
    "        if current_snap == snap:  # if the snapshot has a progenitor\n",
    "            id_progenitors.append(sub['id'])\n",
    "            print(f'Progenitor of {id} at snap={snap} is {sub[\"id\"]}')\n",
    "        else:\n",
    "            print(f'Progenitor of {id} not followed to snap={snap}!')\n",
    "            id_progenitors.append(-1)\n",
    "\n",
    "    progenitor_ids_list.append(id_progenitors)\n",
    "\n",
    "# Transpose the list to match the target_snap order\n",
    "progenitor_ids_list = list(map(list, zip(*progenitor_ids_list)))\n",
    "\n",
    "# Exclude -1 values\n",
    "progenitor_ids_list = [sublist for sublist in progenitor_ids_list if sublist != [-1]*len(ids)]\n",
    "\n",
    "# Flatten the list\n",
    "progenitor_ids_list = [id for sublist in progenitor_ids_list for id in sublist]\n",
    "\n",
    "# Reverse the list\n",
    "progenitor_ids_list.reverse()\n",
    "\n",
    "print(progenitor_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 60, 68, 85, 103, 135]\n",
      "[55141, 68043, 106855, 195558, 192798, 305959]\n"
     ]
    }
   ],
   "source": [
    "# target snapshots\n",
    "snapshots = [54, 60, 68, 85, 103, 135]\n",
    "print(snapshots)\n",
    "#below are the ids that were found from above\n",
    "ids = progenitor_ids_list\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redshift are stored in the list `redshift`\n",
    "redshift = [4, 3, 2, 1, 0.5, 0]\n",
    "\n",
    "# Create a DataFrame from your data\n",
    "df = pd.DataFrame({\n",
    "    'Redshift (z)': redshift\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Redshift (z)\n",
      "0           4.0\n",
      "1           3.0\n",
      "2           2.0\n",
      "3           1.0\n",
      "4           0.5\n"
     ]
    }
   ],
   "source": [
    "# You can view the first few rows of the DataFrame\n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average divergence at snap=54, id=55141: -10.540335697194278\n",
      "Average divergence at snap=60, id=68043: -9.290087654976606\n",
      "Average divergence at snap=68, id=106855: -4.891973155221894\n",
      "Average divergence at snap=85, id=195558: -4.0501670977844\n",
      "Average divergence at snap=103, id=192798: 0.4099557622048855\n",
      "Average divergence at snap=135, id=305959: 5.580304564829707\n"
     ]
    }
   ],
   "source": [
    "#fuction that calculate's the divergence of the gas relative to the BH position in the galaxy\n",
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adhust as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Load the particle data for the subhalo\n",
    "    part_data = il.snapshot.loadSubhalo(basePath, snap, i, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "    \n",
    "    agn_position = il.groupcat.loadSingle(basePath, snap, subhaloID=i)\n",
    "    agn_position = agn_position['SubhaloPos']\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "    # Print the average divergence\n",
    "    print(f'Average divergence at snap={snap}, id={i}: {average_divergence}')\n",
    "#read the file    \n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence'] = avg_divergence_list\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average divergence at snap=54, galaxy id=55141, halo id=1653: -11.70368749269247\n",
      "Average divergence at snap=60, galaxy id=68043, halo id=974: -9.278331955267847\n",
      "Average divergence at snap=68, galaxy id=106855, halo id=697: -4.036630663581051\n",
      "Average divergence at snap=85, galaxy id=195558, halo id=629: -4.127504497479796\n",
      "Average divergence at snap=103, galaxy id=192798, halo id=208: 7.482354996800005\n",
      "Average divergence at snap=135, galaxy id=305959, halo id=272: 4.642933775007915\n"
     ]
    }
   ],
   "source": [
    "#fuction that calculate's the divergence of the gas relative to the BH position in the Halo\n",
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adjusted as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and their snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snap, subhaloID=i)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snap, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snap, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "    # Print the average divergence\n",
    "    print(f'Average divergence at snap={snap}, galaxy id={i}, halo id={main_halo_id}: {average_divergence}')\n",
    "#read the file    \n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence of Halo'] = avg_divergence_list\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average radial velocity at snap=54, id=55141, halo id=1653: nan\n",
      "Average radial velocity at snap=60, id=68043, halo id=974: -230.07628750708975\n",
      "Average radial velocity at snap=68, id=106855, halo id=697: -97.78975728792986\n",
      "Average radial velocity at snap=85, id=195558, halo id=629: -69.78676057960624\n",
      "Average radial velocity at snap=103, id=192798, halo id=208: -48.746116667697294\n",
      "Average radial velocity at snap=135, id=305959, halo id=272: 66.65129063029593\n"
     ]
    }
   ],
   "source": [
    "#fuction that calculate's the radial velocity of the gas relative to the BH position in the galaxy\n",
    "def calculate_radial_velocity(positions, velocities, agn_position):\n",
    "    # Calculate the relative positions and distances of the particles\n",
    "    relative_positions = positions - agn_position\n",
    "    distances = np.linalg.norm(relative_positions, axis=1)\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = np.sum(relative_positions * velocities, axis=1) / distances\n",
    "\n",
    "    return radial_velocities\n",
    "\n",
    "# Define lists to store the results\n",
    "average_radial_velocity_list = []\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snap, subhaloID=i)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snap, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snap, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = calculate_radial_velocity(part_data['Coordinates'], part_data['Velocities'], agn_position)\n",
    "\n",
    "    # Calculate the average radial velocity\n",
    "    average_radial_velocity = np.mean(radial_velocities)\n",
    "    \n",
    "    average_radial_velocity_list.append(average_radial_velocity)\n",
    "\n",
    "    # Print the average radial velocity\n",
    "    print(f'Average radial velocity at snap={snap}, id={i}, halo id={main_halo_id}: {average_radial_velocity}')\n",
    "    \n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['Average radial velocity'] = average_radial_velocity_list\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackhole Masses at snap=54, id=55141: 5.524257081657102\n",
      "Blackhole Masses at snap=60, id=68043: 6.497566912618314\n",
      "Blackhole Masses at snap=68, id=106855: 7.211136649140027\n",
      "Blackhole Masses at snap=85, id=195558: 7.351369191241512\n",
      "Blackhole Masses at snap=103, id=192798: 7.972280368105746\n",
      "Blackhole Masses at snap=135, id=305959: 8.778437294319545\n"
     ]
    }
   ],
   "source": [
    "# List to store BH masses\n",
    "bhmass_values = []\n",
    "\n",
    "fields = 'BH_Mass'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, id in zip(snapshots, ids):\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snap, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_mass = bh_data[0] * ((1e10) / h) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mass' in bh_data and len(bh_data['BH_Mass']) > 0:  # Check if there is BH data.\n",
    "        bh_mass = bh_data['BH_Mass'][0] * ((1e10) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_mass = np.log10(bh_mass)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmass_values.append(bh_mass)\n",
    "    \n",
    "    print(f'Blackhole Masses at snap={snap}, id={id}: {bh_mass}')\n",
    "    \n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['Blackhole Masses'] = bhmass_values\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhmdot:\n",
      "[22.71530800944891, 24.484097204982703, 21.329509413572435, 19.9586552074289, 24.725514656953813, 24.427875661216024]\n"
     ]
    }
   ],
   "source": [
    "# List to store BHmdot\n",
    "bhmdot_values = []\n",
    "\n",
    "fields = 'BH_Mdot'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, id in zip(snapshots, ids):\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snap, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BHmdot.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_dot = bh_data[0] * ((1e10 * Msun) / (h * Gyr_to_s)) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mdot' in bh_data and len(bh_data['BH_Mdot']) > 0:  # Check if there is BH data.\n",
    "        bh_dot = bh_data['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  # If no BHmdot, set the BHmdot to zero.\n",
    "        bh_dot = 0.0\n",
    "        \n",
    "    #covert the BHmdot to log10 \n",
    "    bh_dot = np.log10(bh_dot)\n",
    "\n",
    "    # Append the BHmdot to the list.\n",
    "    bhmdot_values.append(bh_dot)\n",
    "    \n",
    "    \n",
    "# Print the BHmdot\n",
    "print(\"Bhmdot:\")\n",
    "print(bhmdot_values) \n",
    "\n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['Bhmdot'] = bhmdot_values\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subhalo SFR at snap=54, id=55141: 1.874635934829712\n",
      "Subhalo SFR at snap=60, id=68043: 7.331963539123535\n",
      "Subhalo SFR at snap=68, id=106855: 11.120349884033203\n",
      "Subhalo SFR at snap=85, id=195558: 11.676556587219238\n",
      "Subhalo SFR at snap=103, id=192798: 34.291831970214844\n",
      "Subhalo SFR at snap=135, id=305959: 0.4768887162208557\n"
     ]
    }
   ],
   "source": [
    "# List to store Star formation rate\n",
    "sfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    #load the galaxies\n",
    "    sfr = il.groupcat.loadSingle(basePath, snap, subhaloID=i)\n",
    "    #extract the value of the sfr\n",
    "    sfr_value = sfr['SubhaloSFRinHalfRad']\n",
    "    sfr_values.append(sfr_value)\n",
    "    print(f'Subhalo SFR at snap={snap}, id={i}: {sfr_value}')\n",
    "\n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['SFR'] = sfr_values\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eddington rate λ values [0.2219400398908138, 1.3858461649060991, 0.00018774029519565033, 5.787230072257482e-06, 0.08098769167630993, 0.006377098114638177]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store Eddington rate values\n",
    "λ_rate_list = []\n",
    "\n",
    "fields=['BH_Mass', 'BH_Mdot']\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    if blackholes and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = 0.0  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "        \n",
    "    if blackholes and 'BH_Mass' in blackholes and len(blackholes['BH_Mass']) > 0 and blackholes['BH_Mass'][0] != 0: \n",
    "        bh_mass = blackholes['BH_Mass'][0] * ((1e10* Msun) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "\n",
    "    # Calculate L_bol and L_edd\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "    \n",
    "    L_edd = 4 * np.pi * G * bh_mass * m_p * c / sigma_T\n",
    "        \n",
    "    # Calculate λ_rate\n",
    "    λ_rate = (L_bol / L_edd) if L_edd != 0 else 0\n",
    "\n",
    "    # Append λ_rate to the list\n",
    "    λ_rate_list.append(λ_rate)\n",
    "\n",
    "# Print Eddington rate values\n",
    "print(\"Eddington rate λ values\", λ_rate_list)\n",
    "\n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['λ'] = λ_rate_list\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bol Luminosity values:\n",
      "[42.96997941096875, 44.73876860650254, 41.584180815092274, 40.21332660894874, 44.98018605847365, 44.682547062735864]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the bolometric luminosity values\n",
    "L_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting L_bol will be np.nan.\n",
    "\n",
    "    # Calculate L_bol\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append bolometric luminosity to the list\n",
    "    L_list.append(np.log10(L_bol))\n",
    "\n",
    "\n",
    "# Print bolometric luminosity values\n",
    "print(\"Bol Luminosity values:\")\n",
    "print(L_list)\n",
    "\n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['L_bol'] = L_list\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edd Luminosity values:\n",
      "[43.62374375121096, 44.59705358217217, 45.310623318693885, 45.45085586079537, 46.071767037659605, 46.87792396387341]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the Eddington luminosity values\n",
    "L_edd_list = []\n",
    "\n",
    "e_r = 0.2\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    if blackholes and 'BH_Mass' in blackholes and len(blackholes['BH_Mass']) > 0 and blackholes['BH_Mass'][0] != 0: \n",
    "        bh_mass = blackholes['BH_Mass'][0] * ((1e10* Msun) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "\n",
    "    # Calculate L_edd\n",
    "    L_edd = 4 * np.pi * G * bh_mass * m_p * c / sigma_T\n",
    "\n",
    "    \n",
    "    # Append Eddington luminosity to the list\n",
    "    L_edd_list.append(np.log10(L_edd))\n",
    "\n",
    "\n",
    "# Print Eddington luminosity values\n",
    "print(\"Edd Luminosity values:\")\n",
    "print(L_edd_list)\n",
    "\n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['L_edd'] = L_edd_list\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_feed values:\n",
      "[42.27100940663273, 44.03979860216652, 40.885210810756256, 39.51435660461272, 44.28121605413763, 43.983577058399845]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the feedback energy of the AGN\n",
    "E_feed_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting feedback energy will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate feedback energy\n",
    "    E_feed = e_fm * e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append feedback energy to the list\n",
    "    E_feed_list.append(np.log10(E_feed))\n",
    "\n",
    "\n",
    "# Print feedback energy values\n",
    "print(\"E_feed values:\")\n",
    "print(E_feed_list)\n",
    "\n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "df['E_feed'] = E_feed_list\n",
    "df.to_csv('ILL_305959.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No BH_CumEgyInjection_QM data for snap=54, id=55141\n",
      "No BH_CumEgyInjection_QM data for snap=60, id=68043\n",
      "No BH_CumEgyInjection_QM data for snap=68, id=106855\n",
      "No BH_CumEgyInjection_QM data for snap=85, id=195558\n",
      "No BH_CumEgyInjection_QM data for snap=103, id=192798\n",
      "No BH_CumEgyInjection_QM data for snap=135, id=305959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Prepare empty lists to store the BH_CumEgyInjection_QM\n",
    "QM_values = []\n",
    "\n",
    "# Loop over each subhalo ID and their snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load necessary fields\n",
    "    fields = ['BH_CumEgyInjection_QM']\n",
    "    data = il.snapshot.loadSubhalo(basePath, snapshot, id, 'BH', fields=fields)\n",
    "    \n",
    "    # Check if 'BH_CumEgyInjection_QM' exists in the data dictionary and if it's not empty\n",
    "    if 'BH_CumEgyInjection_QM' in data and len(data['BH_CumEgyInjection_QM']) > 0:\n",
    "        # Convert units\n",
    "        BH_CumEgyInjection_QM_phys = np.sqrt(data['BH_CumEgyInjection_QM'][0] * 1e10 / 0.7 / (0.978 / 0.7)**2)\n",
    "\n",
    "        # Calculate the BH_CumEgyInjection_QM and replace -inf with 0\n",
    "        QM_log = np.log10(BH_CumEgyInjection_QM_phys)\n",
    "\n",
    "        # Replace -inf with 0\n",
    "        if np.isneginf(QM_log):\n",
    "            QM_log = 0\n",
    "\n",
    "        QM_values.append(QM_log)\n",
    "\n",
    "        print(f'Logarithmic QM at snap={snapshot}, id={id}: {QM_log}')\n",
    "    else:\n",
    "        print(f'No BH_CumEgyInjection_QM data for snap={snapshot}, id={id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Redshift (z)  Average divergence  Average radial velocity  \\\n",
      "0           4.0          -10.594588                      NaN   \n",
      "1           3.0           -9.338459              -181.328333   \n",
      "2           2.0           -4.977905               -70.544716   \n",
      "3           1.0           -4.051704               -66.025966   \n",
      "4           0.5            0.375005               -19.598002   \n",
      "\n",
      "   Blackhole Masses     Bhmdot        SFR         λ      L_bol      L_edd  \\\n",
      "0          5.524257  22.715308   1.874636  0.221940  42.969979  43.623744   \n",
      "1          6.497567  24.484097   7.331964  1.385846  44.738769  44.597054   \n",
      "2          7.211137  21.329509  11.120350  0.000188  41.584181  45.310623   \n",
      "3          7.351369  19.958655  11.676557  0.000006  40.213327  45.450856   \n",
      "4          7.972280  24.725515  34.291832  0.080988  44.980186  46.071767   \n",
      "\n",
      "      E_feed  \n",
      "0  42.271009  \n",
      "1  44.039799  \n",
      "2  40.885211  \n",
      "3  39.514357  \n",
      "4  44.281216  \n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('ILL_305959.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next galaxy is id=321863\n",
    "\n",
    "##### same process as the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progenitor of 321863 at snap=135 is 321863\n",
      "Progenitor of 321863 at snap=103 is 218780\n",
      "Progenitor of 321863 at snap=85 is 161702\n",
      "Progenitor of 321863 at snap=68 is 71201\n",
      "Progenitor of 321863 at snap=60 is 48081\n",
      "Progenitor of 321863 at snap=54 is 55206\n",
      "[55206, 48081, 71201, 161702, 218780, 321863]\n"
     ]
    }
   ],
   "source": [
    "ids = [321863] #galaxy id\n",
    "target_snaps = [135, 103, 85, 68, 60, 54]  # list of target snapshots here\n",
    "# the target snapshots list are the 7 out the 10 full snapshots that illustrisTNG have \n",
    "# 135 snapshots corresponds to z=0 and the 54 snapshot to z=4\n",
    "\n",
    "progenitor_ids_list = []\n",
    "\n",
    "for id in ids:\n",
    "    id_progenitors = []\n",
    "    start_url = \"http://www.tng-project.org/api/Illustris-1/snapshots/z=0/subhalos/\" + str(id)\n",
    "    sub = get(start_url)\n",
    "    current_snap = 135\n",
    "\n",
    "    for snap in target_snaps:\n",
    "        while current_snap > snap:\n",
    "            # request the full subhalo details of the progenitor by following the sublink URL\n",
    "            try:\n",
    "                sub = get(sub['related']['sublink_progenitor'])\n",
    "                current_snap = sub['snap']\n",
    "            except KeyError:  # KeyError occurs if there's no progenitor\n",
    "                break  # exit the while loop and go to the next snap\n",
    "\n",
    "        if current_snap == snap:  # if the snapshot has a progenitor\n",
    "            id_progenitors.append(sub['id'])\n",
    "            print(f'Progenitor of {id} at snap={snap} is {sub[\"id\"]}')\n",
    "        else:\n",
    "            print(f'Progenitor of {id} not followed to snap={snap}!')\n",
    "            id_progenitors.append(-1)\n",
    "\n",
    "    progenitor_ids_list.append(id_progenitors)\n",
    "\n",
    "# Transpose the list to match the target_snap order\n",
    "progenitor_ids_list = list(map(list, zip(*progenitor_ids_list)))\n",
    "\n",
    "# Exclude -1 values\n",
    "progenitor_ids_list = [sublist for sublist in progenitor_ids_list if sublist != [-1]*len(ids)]\n",
    "\n",
    "# Flatten the list\n",
    "progenitor_ids_list = [id for sublist in progenitor_ids_list for id in sublist]\n",
    "\n",
    "# Reverse the list\n",
    "progenitor_ids_list.reverse()\n",
    "\n",
    "print(progenitor_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 60, 68, 85, 103, 135]\n",
      "[55206, 48081, 71201, 161702, 218780, 321863]\n"
     ]
    }
   ],
   "source": [
    "# target snapshots\n",
    "snapshots = [54, 60, 68, 85, 103, 135]\n",
    "print(snapshots)\n",
    "#below are the ids that were found from above\n",
    "ids = progenitor_ids_list\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redshift are stored in the list `redshift`\n",
    "redshift = [4, 3, 2, 1, 0.5, 0]\n",
    "\n",
    "# Create a DataFrame from your data\n",
    "df = pd.DataFrame({\n",
    "    'Redshift (z)': redshift\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average divergence at snap=54, id=55206: -6.96751112986803\n",
      "Average divergence at snap=60, id=48081: -3.1101808842374234\n",
      "Average divergence at snap=68, id=71201: -4.896644450462997\n",
      "Average divergence at snap=85, id=161702: 6.875333286773741\n",
      "Average divergence at snap=103, id=218780: 0.23513987167227268\n",
      "Average divergence at snap=135, id=321863: 4.54593638033104\n"
     ]
    }
   ],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adhust as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Load the particle data for the subhalo\n",
    "    part_data = il.snapshot.loadSubhalo(basePath, snap, i, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "    \n",
    "    agn_position = il.groupcat.loadSingle(basePath, snap, subhaloID=i)\n",
    "    agn_position = agn_position['SubhaloPos']\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "    # Print the average divergence\n",
    "    print(f'Average divergence at snap={snap}, id={i}: {average_divergence}')\n",
    "#read the file    \n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence'] = avg_divergence_list\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average divergence at snap=54, galaxy id=55206, halo id=1656: -7.244204299779538\n",
      "Average divergence at snap=60, galaxy id=48081, halo id=502: -6.0289983963879346\n",
      "Average divergence at snap=68, galaxy id=71201, halo id=288: -4.101717636060924\n",
      "Average divergence at snap=85, galaxy id=161702, halo id=365: 13.602447231365383\n",
      "Average divergence at snap=103, galaxy id=218780, halo id=313: 1.4799145326639116\n",
      "Average divergence at snap=135, galaxy id=321863, halo id=344: 13.55854560648942\n"
     ]
    }
   ],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adjusted as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and their snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snap, subhaloID=i)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snap, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snap, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "    # Print the average divergence of Halo\n",
    "    print(f'Average divergence at snap={snap}, galaxy id={i}, halo id={main_halo_id}: {average_divergence}')\n",
    "#read the file    \n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence of Halo'] = avg_divergence_list\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average radial velocity at snap=54, id=55206, halo id=1656: -80.94949211664127\n",
      "Average radial velocity at snap=60, id=48081, halo id=502: 27.519725895891664\n",
      "Average radial velocity at snap=68, id=71201, halo id=288: -284.19106285513175\n",
      "Average radial velocity at snap=85, id=161702, halo id=365: 138.06909126845326\n",
      "Average radial velocity at snap=103, id=218780, halo id=313: -295.0325580358673\n",
      "Average radial velocity at snap=135, id=321863, halo id=344: 149.0458912850704\n"
     ]
    }
   ],
   "source": [
    "def calculate_radial_velocity(positions, velocities, agn_position):\n",
    "    # Calculate the relative positions and distances of the particles\n",
    "    relative_positions = positions - agn_position\n",
    "    distances = np.linalg.norm(relative_positions, axis=1)\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = np.sum(relative_positions * velocities, axis=1) / distances\n",
    "\n",
    "    return radial_velocities\n",
    "\n",
    "# Define lists to store the results\n",
    "average_radial_velocity_list = []\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snap, subhaloID=i)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snap, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snap, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = calculate_radial_velocity(part_data['Coordinates'], part_data['Velocities'], agn_position)\n",
    "\n",
    "    # Calculate the average radial velocity\n",
    "    average_radial_velocity = np.mean(radial_velocities)\n",
    "    \n",
    "    average_radial_velocity_list.append(average_radial_velocity)\n",
    "\n",
    "    # Print the average radial velocity\n",
    "    print(f'Average radial velocity at snap={snap}, id={i}, halo id={main_halo_id}: {average_radial_velocity}')\n",
    "    \n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['Average radial velocity'] = average_radial_velocity_list\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackhole Masses at snap=54, id=55206: 6.544635847694498\n",
      "Blackhole Masses at snap=60, id=48081: 6.890266536255159\n",
      "Blackhole Masses at snap=68, id=71201: 7.434814584940885\n",
      "Blackhole Masses at snap=85, id=161702: 8.50232927968103\n",
      "Blackhole Masses at snap=103, id=218780: 8.612044567646167\n",
      "Blackhole Masses at snap=135, id=321863: 8.830848571021425\n"
     ]
    }
   ],
   "source": [
    "# List to store BH masses\n",
    "bhmass_values = []\n",
    "\n",
    "fields = 'BH_Mass'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, id in zip(snapshots, ids):\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snap, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_mass = bh_data[0] * ((1e10) / h) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mass' in bh_data and len(bh_data['BH_Mass']) > 0:  # Check if there is BH data.\n",
    "        bh_mass = bh_data['BH_Mass'][0] * ((1e10) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_mass = np.log10(bh_mass)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmass_values.append(bh_mass)\n",
    "    \n",
    "    print(f'Blackhole Masses at snap={snap}, id={id}: {bh_mass}')\n",
    "    \n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['Blackhole Masses'] = bhmass_values\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhmdot:\n",
      "[23.687527092330058, 23.52077757202463, 23.954258820839932, 23.03122237853417, 24.157074843596273, 16.562664104896324]\n"
     ]
    }
   ],
   "source": [
    "# List to store BHmdot\n",
    "bhmdot_values = []\n",
    "\n",
    "fields = 'BH_Mdot'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, id in zip(snapshots, ids):\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snap, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BHmdot.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_dot = bh_data[0] * ((1e10 * Msun) / (h * Gyr_to_s)) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mdot' in bh_data and len(bh_data['BH_Mdot']) > 0:  # Check if there is BH data.\n",
    "        bh_dot = bh_data['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  # If no BHmdot data, set the BHmdot to zero.\n",
    "        bh_dot = 0.0\n",
    "        \n",
    "    #covert the BHmdot to log10 \n",
    "    bh_dot = np.log10(bh_dot)\n",
    "\n",
    "    # Append the BHmdot to the list.\n",
    "    bhmdot_values.append(bh_dot)\n",
    "    \n",
    "    \n",
    "# Print the BHmdot\n",
    "print(\"Bhmdot:\")\n",
    "print(bhmdot_values) \n",
    "\n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['Bhmdot'] = bhmdot_values\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subhalo SFR at snap=54, id=55206: 3.0659966468811035\n",
      "Subhalo SFR at snap=60, id=48081: 9.99066162109375\n",
      "Subhalo SFR at snap=68, id=71201: 34.09093475341797\n",
      "Subhalo SFR at snap=85, id=161702: 3.7414474487304688\n",
      "Subhalo SFR at snap=103, id=218780: 0.8996496200561523\n",
      "Subhalo SFR at snap=135, id=321863: 0.0\n"
     ]
    }
   ],
   "source": [
    "# List to store Star formation rate\n",
    "sfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    #load the galaxies\n",
    "    sfr = il.groupcat.loadSingle(basePath, snap, subhaloID=i)\n",
    "    #extract the value of the sfr\n",
    "    sfr_value = sfr['SubhaloSFRinHalfRad']\n",
    "    sfr_values.append(sfr_value)\n",
    "    print(f'Subhalo SFR at snap={snap}, id={i}: {sfr_value}')\n",
    "\n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['SFR'] = sfr_values\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eddington rate λ values [0.19864424003403272, 0.06105141972531319, 0.0472747202820977, 0.000483145379771978, 0.0050143541983722765, 7.709039409509626e-11]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store Eddington rate values\n",
    "λ_rate_list = []\n",
    "\n",
    "fields=['BH_Mass', 'BH_Mdot']\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    if blackholes and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = 0.0  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "        \n",
    "    if blackholes and 'BH_Mass' in blackholes and len(blackholes['BH_Mass']) > 0 and blackholes['BH_Mass'][0] != 0: \n",
    "        bh_mass = blackholes['BH_Mass'][0] * ((1e10* Msun) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "\n",
    "    # Calculate L_bol and L_edd\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "    \n",
    "    L_edd = 4 * np.pi * G * bh_mass * m_p * c / sigma_T\n",
    "        \n",
    "    # Calculate λ_rate\n",
    "    λ_rate = (L_bol / L_edd) if L_edd != 0 else 0\n",
    "\n",
    "    # Append λ_rate to the list\n",
    "    λ_rate_list.append(λ_rate)\n",
    "\n",
    "# Print Eddington rate values\n",
    "print(\"Eddington rate λ values\", λ_rate_list)\n",
    "\n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['λ'] = λ_rate_list\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bol Luminosity values:\n",
      "[43.942198493849894, 43.77544897354447, 44.20893022235977, 43.28589378005401, 44.41174624511611, 36.817335506416164]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the bolometric luminosity values\n",
    "L_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting L_bol will be np.nan.\n",
    "\n",
    "    # Calculate L_bol\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append bolometric luminosity to the list\n",
    "    L_list.append(np.log10(L_bol))\n",
    "\n",
    "\n",
    "# Print bolometric luminosity values\n",
    "print(\"Bol Luminosity values:\")\n",
    "print(L_list)\n",
    "\n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['L_bol'] = L_list\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edd Luminosity values:\n",
      "[44.644122517248356, 44.989753205809016, 45.53430125449474, 46.60181594923489, 46.71153123720003, 46.93033524057528]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the Eddington luminosity values\n",
    "L_edd_list = []\n",
    "\n",
    "e_r = 0.2\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    if blackholes and 'BH_Mass' in blackholes and len(blackholes['BH_Mass']) > 0 and blackholes['BH_Mass'][0] != 0: \n",
    "        bh_mass = blackholes['BH_Mass'][0] * ((1e10* Msun) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "\n",
    "    # Calculate L_edd\n",
    "    L_edd = 4 * np.pi * G * bh_mass * m_p * c / sigma_T\n",
    "\n",
    "    \n",
    "    # Append Eddington luminosity to the list\n",
    "    L_edd_list.append(np.log10(L_edd))\n",
    "\n",
    "\n",
    "# Print Eddington luminosity values\n",
    "print(\"Edd Luminosity values:\")\n",
    "print(L_edd_list)\n",
    "\n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['L_edd'] = L_edd_list\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_feed values:\n",
      "[43.243228489513875, 43.07647896920845, 43.50996021802375, 42.58692377571799, 43.712776240780094, 36.118365502080145]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the feedback energy of the AGN values\n",
    "E_feed_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting feedback energy will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate feedback energy\n",
    "    E_feed = e_fm * e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append feedback energy to the list\n",
    "    E_feed_list.append(np.log10(E_feed))\n",
    "\n",
    "\n",
    "# Print feedback energy values\n",
    "print(\"E_feed values:\")\n",
    "print(E_feed_list)\n",
    "\n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "df['E_feed'] = E_feed_list\n",
    "df.to_csv('ILL_321863.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Redshift (z)  Average divergence  Average radial velocity  \\\n",
      "0           4.0           -7.283252               -80.921980   \n",
      "1           3.0           -3.258640                42.515649   \n",
      "2           2.0           -4.933075              -218.486371   \n",
      "3           1.0            6.829896               152.274896   \n",
      "4           0.5            0.220408               -92.871559   \n",
      "\n",
      "   Blackhole Masses     Bhmdot        SFR         λ      L_bol      L_edd  \\\n",
      "0          6.544636  23.687527   3.065997  0.198644  43.942198  44.644123   \n",
      "1          6.890267  23.520778   9.990662  0.061051  43.775449  44.989753   \n",
      "2          7.434815  23.954259  34.090935  0.047275  44.208930  45.534301   \n",
      "3          8.502329  23.031222   3.741447  0.000483  43.285894  46.601816   \n",
      "4          8.612045  24.157075   0.899650  0.005014  44.411746  46.711531   \n",
      "\n",
      "      E_feed  \n",
      "0  43.243228  \n",
      "1  43.076479  \n",
      "2  43.509960  \n",
      "3  42.586924  \n",
      "4  43.712776  \n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('ILL_321863.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next galaxy is id=347122\n",
    "\n",
    "##### same process as the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progenitor of 347122 at snap=135 is 347122\n",
      "Progenitor of 347122 at snap=103 is 252489\n",
      "Progenitor of 347122 at snap=85 is 197241\n",
      "Progenitor of 347122 at snap=68 is 81102\n",
      "Progenitor of 347122 at snap=60 is 37546\n",
      "Progenitor of 347122 at snap=54 is 21803\n",
      "[21803, 37546, 81102, 197241, 252489, 347122]\n"
     ]
    }
   ],
   "source": [
    "ids = [347122] #galaxy id\n",
    "target_snaps = [135, 103, 85, 68, 60, 54]  # list of target snapshots here\n",
    "# the target snapshots list are the 7 out the 10 full snapshots that illustrisTNG have \n",
    "# 135 snapshots corresponds to z=0 and the 54 snapshot to z=4\n",
    "\n",
    "progenitor_ids_list = []\n",
    "\n",
    "for id in ids:\n",
    "    id_progenitors = []\n",
    "    start_url = \"http://www.tng-project.org/api/Illustris-1/snapshots/z=0/subhalos/\" + str(id)\n",
    "    sub = get(start_url)\n",
    "    current_snap = 135\n",
    "\n",
    "    for snap in target_snaps:\n",
    "        while current_snap > snap:\n",
    "            # request the full subhalo details of the progenitor by following the sublink URL\n",
    "            try:\n",
    "                sub = get(sub['related']['sublink_progenitor'])\n",
    "                current_snap = sub['snap']\n",
    "            except KeyError:  # KeyError occurs if there's no progenitor\n",
    "                break  # exit the while loop and go to the next snap\n",
    "\n",
    "        if current_snap == snap:  # if the snapshot has a progenitor\n",
    "            id_progenitors.append(sub['id'])\n",
    "            print(f'Progenitor of {id} at snap={snap} is {sub[\"id\"]}')\n",
    "        else:\n",
    "            print(f'Progenitor of {id} not followed to snap={snap}!')\n",
    "            id_progenitors.append(-1)\n",
    "\n",
    "    progenitor_ids_list.append(id_progenitors)\n",
    "\n",
    "# Transpose the list to match the target_snap order\n",
    "progenitor_ids_list = list(map(list, zip(*progenitor_ids_list)))\n",
    "\n",
    "# Exclude -1 values\n",
    "progenitor_ids_list = [sublist for sublist in progenitor_ids_list if sublist != [-1]*len(ids)]\n",
    "\n",
    "# Flatten the list\n",
    "progenitor_ids_list = [id for sublist in progenitor_ids_list for id in sublist]\n",
    "\n",
    "# Reverse the list\n",
    "progenitor_ids_list.reverse()\n",
    "\n",
    "print(progenitor_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 60, 68, 85, 103, 135]\n",
      "[21803, 37546, 81102, 197241, 252489, 347122]\n"
     ]
    }
   ],
   "source": [
    "# target snapshots\n",
    "snapshots = [54, 60, 68, 85, 103, 135]\n",
    "print(snapshots)\n",
    "#below are the ids that were found from above\n",
    "ids = progenitor_ids_list\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redshift are stored in the list `redshift`\n",
    "redshift = [4, 3, 2, 1, 0.5, 0]\n",
    "\n",
    "# Create a DataFrame from your data\n",
    "df = pd.DataFrame({\n",
    "    'Redshift (z)': redshift\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average divergence at snap=54, id=21803: -6.44623391704116\n",
      "Average divergence at snap=60, id=37546: -3.841097358249396\n",
      "Average divergence at snap=68, id=81102: -0.9402080104565025\n",
      "Average divergence at snap=85, id=197241: -4.368203660908699\n",
      "Average divergence at snap=103, id=252489: 8.824853761133046\n",
      "Average divergence at snap=135, id=347122: 0.18881388621401787\n"
     ]
    }
   ],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adhust as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Load the particle data for the subhalo\n",
    "    part_data = il.snapshot.loadSubhalo(basePath, snap, i, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "    \n",
    "    agn_position = il.groupcat.loadSingle(basePath, snap, subhaloID=i)\n",
    "    agn_position = agn_position['SubhaloPos']\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "    # Print the average divergence\n",
    "    print(f'Average divergence at snap={snap}, id={i}: {average_divergence}')\n",
    "#read the file    \n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence'] = avg_divergence_list\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average divergence at snap=54, galaxy id=21803, halo id=316: -12.254922529696872\n",
      "Average divergence at snap=60, galaxy id=37546, halo id=316: -3.646182159765333\n",
      "Average divergence at snap=68, galaxy id=81102, halo id=380: -0.577607589014709\n",
      "Average divergence at snap=85, galaxy id=197241, halo id=646: -4.622306223710537\n",
      "Average divergence at snap=103, galaxy id=252489, halo id=524: 15.679777889895588\n",
      "Average divergence at snap=135, galaxy id=347122, halo id=494: -0.8461036207897514\n"
     ]
    }
   ],
   "source": [
    "def calculate_divergence(part_data, agn_position):\n",
    "    # Calculate the position of the particles relative to the AGN\n",
    "    relative_pos = part_data['Coordinates'] - agn_position\n",
    "\n",
    "    # Calculate the position boundaries\n",
    "    padding = 1  # This value can be adjusted as needed\n",
    "    min_x, min_y, min_z = np.min(relative_pos, axis=0) - padding\n",
    "    max_x, max_y, max_z = np.max(relative_pos, axis=0) + padding\n",
    "\n",
    "    # Create a grid\n",
    "    grid_x, grid_y, grid_z = np.mgrid[min_x:max_x:100j, min_y:max_y:100j, min_z:max_z:100j]\n",
    "\n",
    "    # Interpolate the velocities onto the grid\n",
    "    grid_vx = interpolate.griddata(relative_pos, part_data['Velocities'][:, 0], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vy = interpolate.griddata(relative_pos, part_data['Velocities'][:, 1], (grid_x, grid_y, grid_z), method='nearest')\n",
    "    grid_vz = interpolate.griddata(relative_pos, part_data['Velocities'][:, 2], (grid_x, grid_y, grid_z), method='nearest')\n",
    "\n",
    "    # Calculate the divergence\n",
    "    divergence = np.gradient(grid_vx, axis=0) + np.gradient(grid_vy, axis=1) + np.gradient(grid_vz, axis=2)\n",
    "    \n",
    "    # Return the average divergence    \n",
    "    return np.mean(divergence)\n",
    "\n",
    "# Define lists to store the results\n",
    "avg_divergence_list = []\n",
    "\n",
    "# Loop over each subhalo ID and their snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snap, subhaloID=i)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snap, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snap, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the divergence\n",
    "    average_divergence = calculate_divergence(part_data, agn_position)\n",
    "\n",
    "    # Store the results\n",
    "    avg_divergence_list.append(average_divergence)\n",
    "\n",
    "    # Print the average divergence\n",
    "    print(f'Average divergence at snap={snap}, galaxy id={i}, halo id={main_halo_id}: {average_divergence}')\n",
    "#read the file    \n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "#append them to the new column \n",
    "df['Average divergence of Halo'] = avg_divergence_list\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average radial velocity at snap=54, id=21803, halo id=316: -117.45271295659464\n",
      "Average radial velocity at snap=60, id=37546, halo id=316: -161.9850355641179\n",
      "Average radial velocity at snap=68, id=81102, halo id=380: -110.14259904952058\n",
      "Average radial velocity at snap=85, id=197241, halo id=646: -22.81455021000121\n",
      "Average radial velocity at snap=103, id=252489, halo id=524: -51.28775805517962\n",
      "Average radial velocity at snap=135, id=347122, halo id=494: -36.103885342898366\n"
     ]
    }
   ],
   "source": [
    "def calculate_radial_velocity(positions, velocities, agn_position):\n",
    "    # Calculate the relative positions and distances of the particles\n",
    "    relative_positions = positions - agn_position\n",
    "    distances = np.linalg.norm(relative_positions, axis=1)\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = np.sum(relative_positions * velocities, axis=1) / distances\n",
    "\n",
    "    return radial_velocities\n",
    "\n",
    "# Define lists to store the results\n",
    "average_radial_velocity_list = []\n",
    "\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    # Get the main halo ID (Group Number) for the subhalo\n",
    "    main_halo_id = il.groupcat.loadSingle(basePath, snap, subhaloID=i)['SubhaloGrNr']\n",
    "    \n",
    "    # Load the properties of the main halo\n",
    "    main_halo_properties = il.groupcat.loadSingle(basePath, snap, haloID=main_halo_id)\n",
    "    \n",
    "    # Get the position of the main halo\n",
    "    agn_position = main_halo_properties['GroupPos']\n",
    "    \n",
    "    # Load the particle data for the halo\n",
    "    part_data = il.snapshot.loadHalo(basePath, snap, main_halo_id, partType='gas', fields=['Coordinates', 'Velocities'])\n",
    "\n",
    "    # Calculate the radial velocities\n",
    "    radial_velocities = calculate_radial_velocity(part_data['Coordinates'], part_data['Velocities'], agn_position)\n",
    "\n",
    "    # Calculate the average radial velocity\n",
    "    average_radial_velocity = np.mean(radial_velocities)\n",
    "    \n",
    "    average_radial_velocity_list.append(average_radial_velocity)\n",
    "\n",
    "    # Print the average radial velocity\n",
    "    print(f'Average radial velocity at snap={snap}, id={i}, halo id={main_halo_id}: {average_radial_velocity}')\n",
    "    \n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['Average radial velocity'] = average_radial_velocity_list\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackhole Masses at snap=54, id=21803: 6.723656159219463\n",
      "Blackhole Masses at snap=60, id=37546: 7.656816910595308\n",
      "Blackhole Masses at snap=68, id=81102: 8.27996336076211\n",
      "Blackhole Masses at snap=85, id=197241: 8.372110455916253\n",
      "Blackhole Masses at snap=103, id=252489: 8.493090537757562\n",
      "Blackhole Masses at snap=135, id=347122: 8.597647335053157\n"
     ]
    }
   ],
   "source": [
    "# List to store BH masses\n",
    "bhmass_values = []\n",
    "\n",
    "fields = 'BH_Mass'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, id in zip(snapshots, ids):\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snap, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_mass = bh_data[0] * ((1e10) / h) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mass' in bh_data and len(bh_data['BH_Mass']) > 0:  # Check if there is BH data.\n",
    "        bh_mass = bh_data['BH_Mass'][0] * ((1e10) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_mass = np.log10(bh_mass)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmass_values.append(bh_mass)\n",
    "    \n",
    "    print(f'Blackhole Masses at snap={snap}, id={id}: {bh_mass}')\n",
    "    \n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['Blackhole Masses'] = bhmass_values\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhmdot:\n",
      "[24.371712281387207, 23.86099294265594, 23.818116675377517, 24.352828458083476, 24.678302314215745, 23.347276409708716]\n"
     ]
    }
   ],
   "source": [
    "# List to store BHmdot\n",
    "bhmdot_values = []\n",
    "\n",
    "fields = 'BH_Mdot'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, id in zip(snapshots, ids):\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snap, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BHmdot.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_dot = bh_data[0] * ((1e10 * Msun) / (h * Gyr_to_s)) #covert the BHmdot\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mdot' in bh_data and len(bh_data['BH_Mdot']) > 0:  # Check if there is BH data.\n",
    "        bh_dot = bh_data['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  # If no BHmdot data, set the BHmdot to zero.\n",
    "        bh_dot = 0.0\n",
    "        \n",
    "    #covert the BHmdot to log10 \n",
    "    bh_dot = np.log10(bh_dot)\n",
    "\n",
    "    # Append the BHmdot to the list.\n",
    "    bhmdot_values.append(bh_dot)\n",
    "    \n",
    "    \n",
    "# Print the BHmdot\n",
    "print(\"Bhmdot:\")\n",
    "print(bhmdot_values) \n",
    "\n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['Bhmdot'] = bhmdot_values\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subhalo SFR at snap=54, id=21803: 2.4654717445373535\n",
      "Subhalo SFR at snap=60, id=37546: 29.487083435058594\n",
      "Subhalo SFR at snap=68, id=81102: 7.017075061798096\n",
      "Subhalo SFR at snap=85, id=197241: 2.5056843757629395\n",
      "Subhalo SFR at snap=103, id=252489: 0.2741098999977112\n",
      "Subhalo SFR at snap=135, id=347122: 0.2927980124950409\n"
     ]
    }
   ],
   "source": [
    "# List to store Star formation rate\n",
    "sfr_values = []\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, i in zip(snapshots, ids):\n",
    "    #load the galaxies\n",
    "    sfr = il.groupcat.loadSingle(basePath, snap, subhaloID=i)\n",
    "    #extract the value of the sfr\n",
    "    sfr_value = sfr['SubhaloSFRinHalfRad']\n",
    "    sfr_values.append(sfr_value)\n",
    "    print(f'Subhalo SFR at snap={snap}, id={i}: {sfr_value}')\n",
    "\n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['SFR'] = sfr_values\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eddington rate λ values [0.6356833759363, 0.022874982159498916, 0.004935578305231227, 0.013674225393335165, 0.021897599501231824, 0.0008031817034028188]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store Eddington rate values\n",
    "λ_rate_list = []\n",
    "\n",
    "fields=['BH_Mass', 'BH_Mdot']\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "\n",
    "    if blackholes and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = 0.0  # Set to np.nan so that the resulting λ_rate will be np.nan.\n",
    "        \n",
    "    if blackholes and 'BH_Mass' in blackholes and len(blackholes['BH_Mass']) > 0 and blackholes['BH_Mass'][0] != 0: \n",
    "        bh_mass = blackholes['BH_Mass'][0] * ((1e10* Msun) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "\n",
    "    # Calculate L_bol and L_edd\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "    \n",
    "    L_edd = 4 * np.pi * G * bh_mass * m_p * c / sigma_T\n",
    "        \n",
    "    # Calculate λ_rate\n",
    "    λ_rate = (L_bol / L_edd) if L_edd != 0 else 0\n",
    "\n",
    "    # Append λ_rate to the list\n",
    "    λ_rate_list.append(λ_rate)\n",
    "\n",
    "# Print Eddington rate values\n",
    "print(\"Eddington rate λ values\", λ_rate_list)\n",
    "\n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['λ'] = λ_rate_list\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bol Luminosity values:\n",
      "[44.62638368290705, 44.11566434417578, 44.07278807689735, 44.60749985960331, 44.932973715735585, 43.601947811228555]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the bolometric luminosity values\n",
    "L_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting L_bol will be np.nan.\n",
    "\n",
    "    # Calculate L_bol\n",
    "    L_bol = e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append bolometric luminosity to the list\n",
    "    L_list.append(np.log10(L_bol))\n",
    "\n",
    "\n",
    "# Print bolometric luminosity values\n",
    "print(\"Bol Luminosity values:\")\n",
    "print(L_list)\n",
    "\n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['L_bol'] = L_list\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edd Luminosity values:\n",
      "[44.82314282877332, 45.756303580149165, 46.37945003031597, 46.47159712547011, 46.59257720731142, 46.697134004607015]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the Eddington luminosity values\n",
    "L_edd_list = []\n",
    "\n",
    "e_r = 0.2\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    if blackholes and 'BH_Mass' in blackholes and len(blackholes['BH_Mass']) > 0 and blackholes['BH_Mass'][0] != 0: \n",
    "        bh_mass = blackholes['BH_Mass'][0] * ((1e10* Msun) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "\n",
    "    # Calculate L_edd\n",
    "    L_edd = 4 * np.pi * G * bh_mass * m_p * c / sigma_T\n",
    "\n",
    "    \n",
    "    # Append Eddington luminosity to the list\n",
    "    L_edd_list.append(np.log10(L_edd))\n",
    "\n",
    "\n",
    "# Print Eddington luminosity values\n",
    "print(\"Edd Luminosity values:\")\n",
    "print(L_edd_list)\n",
    "\n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['L_edd'] = L_edd_list\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_feed values:\n",
      "[43.92741367857103, 43.41669433983976, 43.373818072561335, 43.90852985526729, 44.234003711399566, 42.90297780689254]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the feedback energy of the AGN values\n",
    "E_feed_list = []\n",
    "\n",
    "fields=[\"BH_Mass\", \"BH_Mdot\"]\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snapshot, id in zip(snapshots, ids):\n",
    "    # Load black hole properties for specific subhalo\n",
    "    blackholes = il.snapshot.loadSubhalo(basePath, snapshot, id, \"BH\", fields=fields)\n",
    "    \n",
    "    # Calculate the BHdot.\n",
    "    if isinstance(blackholes, np.ndarray) and blackholes.size > 0 and blackholes['BH_Mdot'][0] != 0:  \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    elif isinstance(blackholes, dict) and 'BH_Mdot' in blackholes and len(blackholes['BH_Mdot']) > 0 and blackholes['BH_Mdot'][0] != 0: \n",
    "        bhdot = blackholes['BH_Mdot'][0] * ((1e10 * Msun) / (h * Gyr_to_s))\n",
    "    else:  \n",
    "        bhdot = np.nan  # Set to np.nan so that the resulting feedback energy will be np.nan.\n",
    "\n",
    "        \n",
    "    # Calculate feedback energy\n",
    "    E_feed = e_fm * e_r * bhdot * c**2\n",
    "\n",
    "    \n",
    "    # Append feedback energy to the list\n",
    "    E_feed_list.append(np.log10(E_feed))\n",
    "\n",
    "\n",
    "# Print feedback energy values\n",
    "print(\"E_feed values:\")\n",
    "print(E_feed_list)\n",
    "\n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "df['E_feed'] = E_feed_list\n",
    "df.to_csv('ILL_347122.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Redshift (z)  Average divergence  Average radial velocity  \\\n",
      "0           4.0           -6.451352              -138.197074   \n",
      "1           3.0           -3.934988               -39.687559   \n",
      "2           2.0           -0.886356              -101.731036   \n",
      "3           1.0           -4.319169               -27.106962   \n",
      "4           0.5            8.728567                 6.576777   \n",
      "\n",
      "   Blackhole Masses     Bhmdot        SFR         λ      L_bol      L_edd  \\\n",
      "0          6.723656  24.371712   2.465472  0.635683  44.626384  44.823143   \n",
      "1          7.656817  23.860993  29.487083  0.022875  44.115664  45.756304   \n",
      "2          8.279963  23.818117   7.017075  0.004936  44.072788  46.379450   \n",
      "3          8.372110  24.352828   2.505684  0.013674  44.607500  46.471597   \n",
      "4          8.493091  24.678302   0.274110  0.021898  44.932974  46.592577   \n",
      "\n",
      "      E_feed  \n",
      "0  43.927414  \n",
      "1  43.416694  \n",
      "2  43.373818  \n",
      "3  43.908530  \n",
      "4  44.234004  \n"
     ]
    }
   ],
   "source": [
    "#lets view the compilation of the file \n",
    "df = pd.read_csv('ILL_347122.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see if we can mining values from all the snapshots between from 135 to 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progenitor of 305959 at snap=135 is 305959\n",
      "Progenitor of 305959 at snap=134 is 304327\n",
      "Progenitor of 305959 at snap=133 is 300729\n",
      "Progenitor of 305959 at snap=132 is 299560\n",
      "Progenitor of 305959 at snap=131 is 295211\n",
      "Progenitor of 305959 at snap=130 is 291414\n",
      "Progenitor of 305959 at snap=129 is 287347\n",
      "Progenitor of 305959 at snap=128 is 285031\n",
      "Progenitor of 305959 at snap=127 is 282680\n",
      "Progenitor of 305959 at snap=126 is 279968\n",
      "Progenitor of 305959 at snap=125 is 277583\n",
      "Progenitor of 305959 at snap=124 is 272905\n",
      "Progenitor of 305959 at snap=123 is 270800\n",
      "Progenitor of 305959 at snap=122 is 268684\n",
      "Progenitor of 305959 at snap=121 is 259358\n",
      "Progenitor of 305959 at snap=120 is 256401\n",
      "Progenitor of 305959 at snap=119 is 252788\n",
      "Progenitor of 305959 at snap=118 is 248332\n",
      "Progenitor of 305959 at snap=117 is 239560\n",
      "Progenitor of 305959 at snap=116 is 233940\n",
      "Progenitor of 305959 at snap=115 is 231186\n",
      "Progenitor of 305959 at snap=114 is 228616\n",
      "Progenitor of 305959 at snap=113 is 225268\n",
      "Progenitor of 305959 at snap=112 is 219253\n",
      "Progenitor of 305959 at snap=111 is 215979\n",
      "Progenitor of 305959 at snap=110 is 213226\n",
      "Progenitor of 305959 at snap=109 is 210368\n",
      "Progenitor of 305959 at snap=108 is 208077\n",
      "Progenitor of 305959 at snap=107 is 203627\n",
      "Progenitor of 305959 at snap=106 is 202153\n",
      "Progenitor of 305959 at snap=105 is 197464\n",
      "Progenitor of 305959 at snap=104 is 193822\n",
      "Progenitor of 305959 at snap=103 is 192798\n",
      "Progenitor of 305959 at snap=102 is 188646\n",
      "Progenitor of 305959 at snap=101 is 185169\n",
      "Progenitor of 305959 at snap=100 is 181603\n",
      "Progenitor of 305959 at snap=99 is 176628\n",
      "Progenitor of 305959 at snap=98 is 172995\n",
      "Progenitor of 305959 at snap=97 is 171835\n",
      "Progenitor of 305959 at snap=96 is 167937\n",
      "Progenitor of 305959 at snap=95 is 166041\n",
      "Progenitor of 305959 at snap=94 is 161610\n",
      "Progenitor of 305959 at snap=93 is 156707\n",
      "Progenitor of 305959 at snap=92 is 152389\n",
      "Progenitor of 305959 at snap=91 is 150144\n",
      "Progenitor of 305959 at snap=90 is 147864\n",
      "Progenitor of 305959 at snap=89 is 206236\n",
      "Progenitor of 305959 at snap=88 is 202346\n",
      "Progenitor of 305959 at snap=87 is 200863\n",
      "Progenitor of 305959 at snap=86 is 197244\n",
      "Progenitor of 305959 at snap=85 is 195558\n",
      "Progenitor of 305959 at snap=84 is 193871\n",
      "Progenitor of 305959 at snap=83 is 188477\n",
      "Progenitor of 305959 at snap=82 is 184203\n",
      "Progenitor of 305959 at snap=81 is 180012\n",
      "Progenitor of 305959 at snap=80 is 173358\n",
      "Progenitor of 305959 at snap=79 is 169934\n",
      "Progenitor of 305959 at snap=78 is 165663\n",
      "Progenitor of 305959 at snap=77 is 158090\n",
      "Progenitor of 305959 at snap=76 is 152791\n",
      "Progenitor of 305959 at snap=75 is 144814\n",
      "Progenitor of 305959 at snap=74 is 140633\n",
      "Progenitor of 305959 at snap=73 is 136485\n",
      "Progenitor of 305959 at snap=72 is 132503\n",
      "Progenitor of 305959 at snap=71 is 125350\n",
      "Progenitor of 305959 at snap=70 is 119358\n",
      "Progenitor of 305959 at snap=69 is 114805\n",
      "Progenitor of 305959 at snap=68 is 106855\n",
      "Progenitor of 305959 at snap=67 is 97305\n",
      "Progenitor of 305959 at snap=66 is 88343\n",
      "Progenitor of 305959 at snap=65 is 87278\n",
      "Progenitor of 305959 at snap=64 is 78952\n",
      "Progenitor of 305959 at snap=63 is 73810\n",
      "Progenitor of 305959 at snap=62 is 66957\n",
      "Progenitor of 305959 at snap=61 is 64393\n",
      "Progenitor of 305959 at snap=60 is 68043\n",
      "Progenitor of 305959 at snap=59 is 64854\n",
      "Progenitor of 305959 at snap=58 is 56639\n",
      "Progenitor of 305959 at snap=57 is 48019\n",
      "Progenitor of 305959 at snap=56 is 43158\n",
      "Progenitor of 305959 not followed to snap=55!\n",
      "Progenitor of 305959 at snap=54 is 55141\n",
      "[55141, 43158, 48019, 56639, 64854, 68043, 64393, 66957, 73810, 78952, 87278, 88343, 97305, 106855, 114805, 119358, 125350, 132503, 136485, 140633, 144814, 152791, 158090, 165663, 169934, 173358, 180012, 184203, 188477, 193871, 195558, 197244, 200863, 202346, 206236, 147864, 150144, 152389, 156707, 161610, 166041, 167937, 171835, 172995, 176628, 181603, 185169, 188646, 192798, 193822, 197464, 202153, 203627, 208077, 210368, 213226, 215979, 219253, 225268, 228616, 231186, 233940, 239560, 248332, 252788, 256401, 259358, 268684, 270800, 272905, 277583, 279968, 282680, 285031, 287347, 291414, 295211, 299560, 300729, 304327, 305959]\n"
     ]
    }
   ],
   "source": [
    "ids = [305959] #galaxy id\n",
    "#target_snaps = [135, 103, 85, 68, 60, 54]  # list of target snapshots here\n",
    "snapsh = list(range(135, 53, -1))\n",
    "# the target snapshots list are the 7 out the 10 full snapshots that illustrisTNG have \n",
    "# 135 snapshots corresponds to z=0 and the 54 snapshot to z=4\n",
    "\n",
    "progenitor_ids_list = []\n",
    "\n",
    "for id in ids:\n",
    "    id_progenitors = []\n",
    "    start_url = \"http://www.tng-project.org/api/Illustris-1/snapshots/z=0/subhalos/\" + str(id)\n",
    "    sub = get(start_url)\n",
    "    current_snap = 135\n",
    "\n",
    "    for snap in target_snaps:\n",
    "        while current_snap > snap:\n",
    "            # request the full subhalo details of the progenitor by following the sublink URL\n",
    "            try:\n",
    "                sub = get(sub['related']['sublink_progenitor'])\n",
    "                current_snap = sub['snap']\n",
    "            except KeyError:  # KeyError occurs if there's no progenitor\n",
    "                break  # exit the while loop and go to the next snap\n",
    "\n",
    "        if current_snap == snap:  # if the snapshot has a progenitor\n",
    "            id_progenitors.append(sub['id'])\n",
    "            print(f'Progenitor of {id} at snap={snap} is {sub[\"id\"]}')\n",
    "        else:\n",
    "            print(f'Progenitor of {id} not followed to snap={snap}!')\n",
    "            id_progenitors.append(-1)\n",
    "\n",
    "    progenitor_ids_list.append(id_progenitors)\n",
    "\n",
    "# Transpose the list to match the target_snap order\n",
    "progenitor_ids_list = list(map(list, zip(*progenitor_ids_list)))\n",
    "\n",
    "# Exclude -1 values\n",
    "progenitor_ids_list = [sublist for sublist in progenitor_ids_list if sublist != [-1]*len(ids)]\n",
    "\n",
    "# Flatten the list\n",
    "progenitor_ids_list = [id for sublist in progenitor_ids_list for id in sublist]\n",
    "\n",
    "# Reverse the list\n",
    "progenitor_ids_list.reverse()\n",
    "\n",
    "print(progenitor_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 3.950617283950617, 3.901234567901234, 3.8518518518518516, 3.802469135802469, 3.753086419753086, 3.7037037037037033, 3.654320987654321, 3.6049382716049383, 3.5555555555555554, 3.5061728395061724, 3.45679012345679, 3.4074074074074074, 3.3580246913580245, 3.3086419753086416, 3.259259259259259, 3.2098765432098766, 3.1604938271604937, 3.1111111111111107, 3.0617283950617282, 3.0123456790123457, 2.962962962962963, 2.91358024691358, 2.8641975308641974, 2.814814814814815, 2.765432098765432, 2.716049382716049, 2.6666666666666665, 2.617283950617284, 2.567901234567901, 2.518518518518518, 2.4691358024691357, 2.419753086419753, 2.3703703703703702, 2.3209876543209873, 2.271604938271605, 2.2222222222222223, 2.1728395061728394, 2.1234567901234565, 2.074074074074074, 2.0246913580246915, 1.9753086419753085, 1.9259259259259258, 1.876543209876543, 1.8271604938271604, 1.7777777777777777, 1.728395061728395, 1.6790123456790123, 1.6296296296296295, 1.5802469135802468, 1.5308641975308641, 1.4814814814814814, 1.4320987654320987, 1.382716049382716, 1.3333333333333333, 1.2839506172839505, 1.2345679012345678, 1.1851851851851851, 1.1358024691358024, 1.0864197530864197, 1.037037037037037, 0.9876543209876543, 0.9382716049382716, 0.8888888888888888, 0.8395061728395061, 0.7901234567901234, 0.7407407407407407, 0.691358024691358, 0.6419753086419753, 0.5925925925925926, 0.5432098765432098, 0.49382716049382713, 0.4444444444444444, 0.3950617283950617, 0.345679012345679, 0.2962962962962963, 0.24691358024691357, 0.19753086419753085, 0.14814814814814814, 0.09876543209876543, 0.04938271604938271, -0.0]\n"
     ]
    }
   ],
   "source": [
    "def snapshot_to_redshift(snapshot):\n",
    "    m = (4 - 0) / (54 - 135)  # Slope of the line\n",
    "    return m * (snapshot - 135)\n",
    "\n",
    "# This is your list of snapshots\n",
    "target_snaps = list(range(135, 53, -1))\n",
    "\n",
    "# Now, you can create a new list of redshifts corresponding to your list of snapshots\n",
    "target_redshifts = [snapshot_to_redshift(snapshot) for snapshot in target_snaps]\n",
    "\n",
    "target_redshifts.reverse()\n",
    "\n",
    "print(target_redshifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from your data\n",
    "df = pd.DataFrame({\n",
    "    'Redshift (z)': target_redshifts\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = progenitor_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapsh = list(range(54, 136))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blackhole Masses at snap=54, id=55141: 5.524257081657102\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Can't open attribute (can't locate attribute: 'FileOffsets_Snap')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-8503efb0c0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msnap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapsh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Load the BH data for this snapshot and subhalo ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbh_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadSubhalo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BH\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Calculate the BH mass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/illustris_python/snapshot.py\u001b[0m in \u001b[0;36mloadSubhalo\u001b[0;34m(basePath, snapNum, id, partType, fields)\u001b[0m\n\u001b[1;32m    189\u001b[0m         (optionally restricted to a subset fields). \"\"\"\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# load subhalo length, compute offset, call loadSubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSnapOffsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Subhalo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloadSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/illustris_python/snapshot.py\u001b[0m in \u001b[0;36mgetSnapOffsets\u001b[0;34m(basePath, snapNum, id, type)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mgroupFileOffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FileOffsets_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'snapOffsets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FileOffsets_Snap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# calculate target groups file chunk which contains this id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h5py/_hl/attrs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\" Read the value of an attribute.\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5a.pyx\u001b[0m in \u001b[0;36mh5py.h5a.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Can't open attribute (can't locate attribute: 'FileOffsets_Snap')\""
     ]
    }
   ],
   "source": [
    "# List to store BH masses\n",
    "bhmass_values = []\n",
    "\n",
    "fields = 'BH_Mass'\n",
    "\n",
    "# Loop over each subhalo ID and there snapshot\n",
    "for snap, id in zip(snapsh, ids):\n",
    "    # Load the BH data for this snapshot and subhalo ID.\n",
    "    bh_data = il.snapshot.loadSubhalo(basePath, snap, id, \"BH\", fields=fields)\n",
    "\n",
    "    # Calculate the BH mass.\n",
    "    if isinstance(bh_data, np.ndarray) and bh_data.size > 0:  # Check if bh_data is a non-empty array.\n",
    "        bh_mass = bh_data[0] * ((1e10) / h) #covert the bh mases\n",
    "    elif isinstance(bh_data, dict) and 'BH_Mass' in bh_data and len(bh_data['BH_Mass']) > 0:  # Check if there is BH data.\n",
    "        bh_mass = bh_data['BH_Mass'][0] * ((1e10) / h)\n",
    "    else:  # If no BH data, set the BH mass to zero.\n",
    "        bh_mass = 0.0\n",
    "        \n",
    "    #covert the bh masess to log10 \n",
    "    bh_mass = np.log10(bh_mass)\n",
    "\n",
    "    # Append the BH mass to the list.\n",
    "    bhmass_values.append(bh_mass)\n",
    "    \n",
    "    print(f'Blackhole Masses at snap={snap}, id={id}: {bh_mass}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is not possible to mine data for mini snapshots, because they do not have all the data that it needs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
